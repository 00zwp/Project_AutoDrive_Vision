<?xml version="1.0" ?>
<net name="torch_jit" version="11">
	<layers>
		<layer id="0" name="x.1" type="Parameter" version="opset1">
			<data element_type="f32" shape="1,3,512,1024"/>
			<rt_info>
				<attribute name="fused_names" value="x.1" version="0"/>
				<attribute name="old_api_map_element_type" value="f16" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="x.1" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>512</dim>
					<dim>1024</dim>
				</port>
			</output>
		</layer>
		<layer id="1" name="Constant_6833_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="0" shape="1, 3, 1, 1" size="6"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2" name="Constant_6833" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_6833" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3" name="Subtract_6834" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Subtract_6834" version="0"/>
				<attribute name="preprocessing" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>512</dim>
					<dim>1024</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>512</dim>
					<dim>1024</dim>
				</port>
			</output>
		</layer>
		<layer id="4" name="Constant_93321_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="6" shape="16, 3, 3, 3" size="864"/>
			<output>
				<port id="0" precision="FP16">
					<dim>16</dim>
					<dim>3</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="5" name="Constant_93321" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_6835, Convolution_347, Divide_6836, Split_215, onnx::Conv_338, onnx::Conv_821" version="0"/>
				<attribute name="preprocessing" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>16</dim>
					<dim>3</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>16</dim>
					<dim>3</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="6" name="Convolution_347" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="1, 1" strides="2, 2"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_6835, Convolution_347, Divide_6836, Split_215, onnx::Conv_338, onnx::Conv_821" version="0"/>
				<attribute name="preprocessing" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>512</dim>
					<dim>1024</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>16</dim>
					<dim>3</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>256</dim>
					<dim>512</dim>
				</port>
			</output>
		</layer>
		<layer id="7" name="Reshape_367_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="870" shape="1, 16, 1, 1" size="32"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="8" name="Reshape_367" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="9" name="input.3" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_366, Reshape_367, input.3" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>256</dim>
					<dim>512</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.3" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>256</dim>
					<dim>512</dim>
				</port>
			</output>
		</layer>
		<layer id="10" name="Constant_395_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="11" name="Constant_395" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_395" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="12" name="Constant_396_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="13" name="Constant_396" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_396" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="14" name="onnx::Mul_341" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_341" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>256</dim>
					<dim>512</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_341" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>256</dim>
					<dim>512</dim>
				</port>
			</output>
		</layer>
		<layer id="15" name="onnx::Shape_342" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Shape_342" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>256</dim>
					<dim>512</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>256</dim>
					<dim>512</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Shape_342" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>256</dim>
					<dim>512</dim>
				</port>
			</output>
		</layer>
		<layer id="16" name="onnx::Sub_351" type="Const" version="opset1">
			<data element_type="i64" offset="906" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Sub_351" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Sub_351" precision="I64"/>
			</output>
		</layer>
		<layer id="17" name="onnx::Gather_346" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Gather_343, onnx::Gather_346" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>256</dim>
					<dim>512</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Gather_343,onnx::Gather_346" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="18" name="onnx::Gather_347" type="Const" version="opset1">
			<data element_type="i64" offset="914" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Gather_347" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Gather_347" precision="I64"/>
			</output>
		</layer>
		<layer id="19" name="Constant_405" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_405" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="20" name="onnx::Sub_348" type="Gather" version="opset8">
			<data batch_dims="0"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_405, onnx::Gather_347, onnx::Sub_348" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
				<port id="1" precision="I64"/>
				<port id="2" precision="I64"/>
			</input>
			<output>
				<port id="3" names="onnx::Sub_348" precision="I64"/>
			</output>
		</layer>
		<layer id="21" name="onnx::Div_352" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_352, onnx::Sub_351" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Div_352" precision="I64"/>
			</output>
		</layer>
		<layer id="22" name="onnx::Div_353" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_353" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Div_353" precision="I64"/>
			</output>
		</layer>
		<layer id="23" name="onnx::Cast_354" type="Divide" version="opset1">
			<data auto_broadcast="numpy" m_pythondiv="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_354, onnx::Cast_355, onnx::Div_353, onnx::Unsqueeze_356" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Cast_354,onnx::Cast_355,onnx::Unsqueeze_356" precision="I64"/>
			</output>
		</layer>
		<layer id="24" name="Constant_438" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_438" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="25" name="onnx::Concat_376" type="Unsqueeze" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_438, onnx::Concat_376" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Concat_376" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="26" name="onnx::Div_357" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_357" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Div_357" precision="I64"/>
			</output>
		</layer>
		<layer id="27" name="onnx::Cast_358" type="Divide" version="opset1">
			<data auto_broadcast="numpy" m_pythondiv="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_358, onnx::Cast_359, onnx::Div_357, onnx::Sub_360" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Cast_358,onnx::Cast_359,onnx::Sub_360" precision="I64"/>
			</output>
		</layer>
		<layer id="28" name="onnx::Unsqueeze_361" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Unsqueeze_361" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Unsqueeze_361" precision="I64"/>
			</output>
		</layer>
		<layer id="29" name="Constant_440" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_440" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="30" name="onnx::Concat_377" type="Unsqueeze" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_440, onnx::Concat_377" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Concat_377" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="31" name="onnx::Sub_349" type="Const" version="opset1">
			<data element_type="i64" offset="938" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Sub_349" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Sub_349" precision="I64"/>
			</output>
		</layer>
		<layer id="32" name="onnx::Gather_344" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Gather_344" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Gather_344" precision="I64"/>
			</output>
		</layer>
		<layer id="33" name="Constant_401" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_401" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="34" name="onnx::Sub_345" type="Gather" version="opset8">
			<data batch_dims="0"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_401, onnx::Gather_344, onnx::Sub_345" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
				<port id="1" precision="I64"/>
				<port id="2" precision="I64"/>
			</input>
			<output>
				<port id="3" names="onnx::Sub_345" precision="I64"/>
			</output>
		</layer>
		<layer id="35" name="onnx::Div_350" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_350, onnx::Sub_349" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Div_350" precision="I64"/>
			</output>
		</layer>
		<layer id="36" name="onnx::Div_362" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_362" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Div_362" precision="I64"/>
			</output>
		</layer>
		<layer id="37" name="onnx::Cast_363" type="Divide" version="opset1">
			<data auto_broadcast="numpy" m_pythondiv="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_363, onnx::Cast_364, onnx::Div_362, onnx::Unsqueeze_365" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Cast_363,onnx::Cast_364,onnx::Unsqueeze_365" precision="I64"/>
			</output>
		</layer>
		<layer id="38" name="Constant_442" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_442" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="39" name="onnx::Concat_378" type="Unsqueeze" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_442, onnx::Concat_378" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Concat_378" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="40" name="onnx::Div_366" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_366" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Div_366" precision="I64"/>
			</output>
		</layer>
		<layer id="41" name="onnx::Cast_367" type="Divide" version="opset1">
			<data auto_broadcast="numpy" m_pythondiv="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_367, onnx::Cast_368, onnx::Div_366, onnx::Sub_369" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Cast_367,onnx::Cast_368,onnx::Sub_369" precision="I64"/>
			</output>
		</layer>
		<layer id="42" name="onnx::Unsqueeze_370" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Unsqueeze_370" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Unsqueeze_370" precision="I64"/>
			</output>
		</layer>
		<layer id="43" name="Constant_444" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_444" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="44" name="onnx::Concat_379" type="Unsqueeze" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_444, onnx::Concat_379" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Concat_379" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="45" name="onnx::Cast_380" type="Concat" version="opset1">
			<data axis="0"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_380, onnx::Concat_388" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
				<port id="2" precision="I64">
					<dim>1</dim>
				</port>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="4" names="onnx::Cast_380,onnx::Concat_388" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="46" name="onnx::Concat_389" type="Const" version="opset1">
			<data element_type="i64" offset="946" shape="4" size="32"/>
			<output>
				<port id="0" names="onnx::Concat_389" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="47" name="onnx::Reshape_390" type="Concat" version="opset1">
			<data axis="0"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Concat_389, onnx::ConstantOfShape_387, onnx::Gather_382, onnx::Reshape_390, onnx::Sub_383, onnx::Sub_386" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Reshape_390" precision="I64">
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="48" name="onnx::Reshape_391" type="Const" version="opset1">
			<data element_type="i64" offset="978" shape="2" size="16"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Reshape_391" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Reshape_391" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="49" name="onnx::Slice_392" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Reshape_391, onnx::Slice_392" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>8</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Slice_392" precision="I64">
					<dim>4</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="50" name="onnx::Slice_394" type="Const" version="opset1">
			<data element_type="i64" offset="994" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Slice_393, onnx::Slice_394, onnx::Slice_395, onnx::Slice_396, onnx::Transpose_397" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Slice_394" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="51" name="onnx::Slice_395" type="Const" version="opset1">
			<data element_type="i64" offset="1002" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Slice_393, onnx::Slice_394, onnx::Slice_395, onnx::Slice_396, onnx::Transpose_397" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Slice_395" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="52" name="onnx::Slice_396" type="Const" version="opset1">
			<data element_type="i64" offset="994" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Slice_393, onnx::Slice_394, onnx::Slice_395, onnx::Slice_396, onnx::Transpose_397" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Slice_396" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="53" name="onnx::Transpose_397" type="StridedSlice" version="opset1">
			<data begin_mask="0" ellipsis_mask="" end_mask="0" new_axis_mask="" shrink_axis_mask=""/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Slice_393, onnx::Slice_394, onnx::Slice_395, onnx::Slice_396, onnx::Transpose_397" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
					<dim>2</dim>
				</port>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
				<port id="2" precision="I64">
					<dim>1</dim>
				</port>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="4" names="onnx::Transpose_397" precision="I64">
					<dim>4</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="54" name="Constant_498" type="Const" version="opset1">
			<data element_type="i64" offset="1010" shape="2" size="16"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_498" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="55" name="onnx::Reshape_398" type="Transpose" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_498, onnx::Reshape_398" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
					<dim>2</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Reshape_398" precision="I64">
					<dim>2</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="56" name="onnx::Reshape_399" type="Const" version="opset1">
			<data element_type="i64" offset="994" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Reshape_399" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Reshape_399" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="57" name="onnx::Cast_400" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_400, onnx::Pad_401, onnx::Reshape_399" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>2</dim>
					<dim>4</dim>
				</port>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Cast_400,onnx::Pad_401" precision="I64">
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="58" name="Constant_509" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_509" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="59" name="Split_510" type="Split" version="opset1">
			<data num_splits="2"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_509, Split_510" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>8</dim>
				</port>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" precision="I64">
					<dim>4</dim>
				</port>
				<port id="3" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="60" name="onnx::Pad_402_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1026" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="61" name="onnx::Pad_402" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Pad_402" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" names="onnx::Pad_402" precision="FP32"/>
			</output>
		</layer>
		<layer id="62" name="onnx::Conv_403" type="Pad" version="opset1">
			<data pad_mode="constant"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_403" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>256</dim>
					<dim>512</dim>
				</port>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
				<port id="2" precision="I64">
					<dim>4</dim>
				</port>
				<port id="3" precision="FP32"/>
			</input>
			<output>
				<port id="4" names="onnx::Conv_403" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>257</dim>
					<dim>513</dim>
				</port>
			</output>
		</layer>
		<layer id="63" name="Reshape_899_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1028" shape="16, 1, 1, 3, 3" size="288"/>
			<output>
				<port id="0" precision="FP16">
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="64" name="Reshape_899" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="65" name="GroupConvolution_965" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="2, 2"/>
			<rt_info>
				<attribute name="fused_names" value="GroupConvolution_965, Reshape_899" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>257</dim>
					<dim>513</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="66" name="Reshape_985_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1316" shape="1, 16, 1, 1" size="32"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="67" name="Reshape_985" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="68" name="input.11" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_984, Reshape_985, input.11" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.11" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="69" name="onnx::ReduceMean_406" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::ReduceMean_406" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::ReduceMean_406" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="70" name="Constant_1014" type="Const" version="opset1">
			<data element_type="i64" offset="1348" shape="2" size="16"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_1014" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="71" name="input.15" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<rt_info>
				<attribute name="fused_names" value="input.15" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.15" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="72" name="encoder.model.blocks.0.0.se.conv_reduce.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1364" shape="8, 16, 1, 1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>8</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="73" name="encoder.model.blocks.0.0.se.conv_reduce.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="encoder.model.blocks.0.0.se.conv_reduce.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>8</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="encoder.model.blocks.0.0.se.conv_reduce.weight" precision="FP32">
					<dim>8</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="74" name="Convolution_1016" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_1016" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>8</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="75" name="Reshape_1036_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1620" shape="1, 8, 1, 1" size="16"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="76" name="Reshape_1036" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="77" name="input.19" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_1035, Reshape_1036, input.19" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.19" precision="FP32">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="78" name="onnx::Conv_409" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_409" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_409" precision="FP32">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="79" name="encoder.model.blocks.0.0.se.conv_expand.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1636" shape="16, 8, 1, 1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>16</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="80" name="encoder.model.blocks.0.0.se.conv_expand.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="encoder.model.blocks.0.0.se.conv_expand.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>16</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="encoder.model.blocks.0.0.se.conv_expand.weight" precision="FP32">
					<dim>16</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="81" name="Convolution_1065" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_1065" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>16</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="82" name="Reshape_1085_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1892" shape="1, 16, 1, 1" size="32"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="83" name="Reshape_1085" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="84" name="input.23" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_1084, Reshape_1085, input.23" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.23" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="85" name="Constant_1113_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="86" name="Constant_1113" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_1113" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="87" name="Constant_1114_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="88" name="Constant_1114" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_1114" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="89" name="onnx::Mul_411" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_411" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_411" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="90" name="input.27" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="input.27" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.27" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="91" name="onnx::Conv_827_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1924" shape="16, 16, 1, 1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>16</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="92" name="onnx::Conv_827" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_827" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>16</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_827" precision="FP32">
					<dim>16</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="93" name="Convolution_1117" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_1117" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>16</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="94" name="Reshape_1137_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="2436" shape="1, 16, 1, 1" size="32"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="95" name="Reshape_1137" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="96" name="input.35" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_1136, Reshape_1137, input.35" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.35" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="97" name="onnx::Conv_830_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="2468" shape="72, 16, 1, 1" size="2304"/>
			<output>
				<port id="0" precision="FP16">
					<dim>72</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="98" name="onnx::Conv_830" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_830" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>72</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_830" precision="FP32">
					<dim>72</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="99" name="Convolution_1165" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_1165" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>72</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="100" name="Reshape_1185_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="4772" shape="1, 72, 1, 1" size="144"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="101" name="Reshape_1185" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="102" name="input.43" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_1184, Reshape_1185, input.43" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.43" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="103" name="onnx::Shape_417" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Shape_417" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Shape_417" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="104" name="onnx::Sub_426" type="Const" version="opset1">
			<data element_type="i64" offset="938" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Sub_426" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Sub_426" precision="I64"/>
			</output>
		</layer>
		<layer id="105" name="onnx::Gather_421" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Gather_418, onnx::Gather_421" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Gather_418,onnx::Gather_421" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="106" name="onnx::Gather_422" type="Const" version="opset1">
			<data element_type="i64" offset="914" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Gather_422" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Gather_422" precision="I64"/>
			</output>
		</layer>
		<layer id="107" name="Constant_1220" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_1220" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="108" name="onnx::Sub_423" type="Gather" version="opset8">
			<data batch_dims="0"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_1220, onnx::Gather_422, onnx::Sub_423" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
				<port id="1" precision="I64"/>
				<port id="2" precision="I64"/>
			</input>
			<output>
				<port id="3" names="onnx::Sub_423" precision="I64"/>
			</output>
		</layer>
		<layer id="109" name="onnx::Div_427" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_427, onnx::Sub_426" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Div_427" precision="I64"/>
			</output>
		</layer>
		<layer id="110" name="onnx::Div_428" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_428" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Div_428" precision="I64"/>
			</output>
		</layer>
		<layer id="111" name="onnx::Cast_429" type="Divide" version="opset1">
			<data auto_broadcast="numpy" m_pythondiv="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_429, onnx::Cast_430, onnx::Div_428, onnx::Unsqueeze_431" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Cast_429,onnx::Cast_430,onnx::Unsqueeze_431" precision="I64"/>
			</output>
		</layer>
		<layer id="112" name="Constant_1253" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_1253" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="113" name="onnx::Concat_451" type="Unsqueeze" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_1253, onnx::Concat_451" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Concat_451" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="114" name="onnx::Div_432" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_432" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Div_432" precision="I64"/>
			</output>
		</layer>
		<layer id="115" name="onnx::Cast_433" type="Divide" version="opset1">
			<data auto_broadcast="numpy" m_pythondiv="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_433, onnx::Cast_434, onnx::Div_432, onnx::Sub_435" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Cast_433,onnx::Cast_434,onnx::Sub_435" precision="I64"/>
			</output>
		</layer>
		<layer id="116" name="onnx::Unsqueeze_436" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Unsqueeze_436" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Unsqueeze_436" precision="I64"/>
			</output>
		</layer>
		<layer id="117" name="Constant_1255" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_1255" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="118" name="onnx::Concat_452" type="Unsqueeze" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_1255, onnx::Concat_452" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Concat_452" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="119" name="onnx::Sub_424" type="Const" version="opset1">
			<data element_type="i64" offset="4916" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Sub_424" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Sub_424" precision="I64"/>
			</output>
		</layer>
		<layer id="120" name="onnx::Gather_419" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Gather_419" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Gather_419" precision="I64"/>
			</output>
		</layer>
		<layer id="121" name="Constant_1216" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_1216" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="122" name="onnx::Sub_420" type="Gather" version="opset8">
			<data batch_dims="0"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_1216, onnx::Gather_419, onnx::Sub_420" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
				<port id="1" precision="I64"/>
				<port id="2" precision="I64"/>
			</input>
			<output>
				<port id="3" names="onnx::Sub_420" precision="I64"/>
			</output>
		</layer>
		<layer id="123" name="onnx::Div_425" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_425, onnx::Sub_424" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Div_425" precision="I64"/>
			</output>
		</layer>
		<layer id="124" name="onnx::Div_437" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_437" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Div_437" precision="I64"/>
			</output>
		</layer>
		<layer id="125" name="onnx::Cast_438" type="Divide" version="opset1">
			<data auto_broadcast="numpy" m_pythondiv="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_438, onnx::Cast_439, onnx::Div_437, onnx::Unsqueeze_440" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Cast_438,onnx::Cast_439,onnx::Unsqueeze_440" precision="I64"/>
			</output>
		</layer>
		<layer id="126" name="Constant_1257" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_1257" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="127" name="onnx::Concat_453" type="Unsqueeze" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_1257, onnx::Concat_453" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Concat_453" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="128" name="onnx::Div_441" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_441" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Div_441" precision="I64"/>
			</output>
		</layer>
		<layer id="129" name="onnx::Cast_442" type="Divide" version="opset1">
			<data auto_broadcast="numpy" m_pythondiv="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_442, onnx::Cast_443, onnx::Div_441, onnx::Sub_444" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Cast_442,onnx::Cast_443,onnx::Sub_444" precision="I64"/>
			</output>
		</layer>
		<layer id="130" name="onnx::Unsqueeze_445" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Unsqueeze_445" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Unsqueeze_445" precision="I64"/>
			</output>
		</layer>
		<layer id="131" name="Constant_1259" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_1259" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="132" name="onnx::Concat_454" type="Unsqueeze" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_1259, onnx::Concat_454" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Concat_454" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="133" name="onnx::Cast_455" type="Concat" version="opset1">
			<data axis="0"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_455, onnx::Concat_463" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
				<port id="2" precision="I64">
					<dim>1</dim>
				</port>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="4" names="onnx::Cast_455,onnx::Concat_463" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="134" name="onnx::Concat_464" type="Const" version="opset1">
			<data element_type="i64" offset="946" shape="4" size="32"/>
			<output>
				<port id="0" names="onnx::Concat_464" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="135" name="onnx::Reshape_465" type="Concat" version="opset1">
			<data axis="0"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Concat_464, onnx::ConstantOfShape_462, onnx::Gather_457, onnx::Reshape_465, onnx::Sub_458, onnx::Sub_461" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Reshape_465" precision="I64">
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="136" name="onnx::Reshape_466" type="Const" version="opset1">
			<data element_type="i64" offset="978" shape="2" size="16"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Reshape_466" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Reshape_466" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="137" name="onnx::Slice_467" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Reshape_466, onnx::Slice_467" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>8</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Slice_467" precision="I64">
					<dim>4</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="138" name="onnx::Slice_469" type="Const" version="opset1">
			<data element_type="i64" offset="994" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Slice_468, onnx::Slice_469, onnx::Slice_470, onnx::Slice_471, onnx::Transpose_472" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Slice_469" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="139" name="onnx::Slice_470" type="Const" version="opset1">
			<data element_type="i64" offset="1002" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Slice_468, onnx::Slice_469, onnx::Slice_470, onnx::Slice_471, onnx::Transpose_472" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Slice_470" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="140" name="onnx::Slice_471" type="Const" version="opset1">
			<data element_type="i64" offset="994" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Slice_468, onnx::Slice_469, onnx::Slice_470, onnx::Slice_471, onnx::Transpose_472" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Slice_471" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="141" name="onnx::Transpose_472" type="StridedSlice" version="opset1">
			<data begin_mask="0" ellipsis_mask="" end_mask="0" new_axis_mask="" shrink_axis_mask=""/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Slice_468, onnx::Slice_469, onnx::Slice_470, onnx::Slice_471, onnx::Transpose_472" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
					<dim>2</dim>
				</port>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
				<port id="2" precision="I64">
					<dim>1</dim>
				</port>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="4" names="onnx::Transpose_472" precision="I64">
					<dim>4</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="142" name="Constant_1313" type="Const" version="opset1">
			<data element_type="i64" offset="1010" shape="2" size="16"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_1313" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="143" name="onnx::Reshape_473" type="Transpose" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_1313, onnx::Reshape_473" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
					<dim>2</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Reshape_473" precision="I64">
					<dim>2</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="144" name="onnx::Reshape_474" type="Const" version="opset1">
			<data element_type="i64" offset="994" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Reshape_474" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Reshape_474" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="145" name="onnx::Cast_475" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_475, onnx::Pad_476, onnx::Reshape_474" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>2</dim>
					<dim>4</dim>
				</port>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Cast_475,onnx::Pad_476" precision="I64">
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="146" name="Constant_1324" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_1324" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="147" name="Split_1325" type="Split" version="opset1">
			<data num_splits="2"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_1324, Split_1325" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>8</dim>
				</port>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" precision="I64">
					<dim>4</dim>
				</port>
				<port id="3" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="148" name="onnx::Pad_477_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1026" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="149" name="onnx::Pad_477" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Pad_477" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" names="onnx::Pad_477" precision="FP32"/>
			</output>
		</layer>
		<layer id="150" name="onnx::Conv_478" type="Pad" version="opset1">
			<data pad_mode="constant"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_478" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
				<port id="2" precision="I64">
					<dim>4</dim>
				</port>
				<port id="3" precision="FP32"/>
			</input>
			<output>
				<port id="4" names="onnx::Conv_478" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>129</dim>
					<dim>257</dim>
				</port>
			</output>
		</layer>
		<layer id="151" name="Reshape_1714_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="4924" shape="72, 1, 1, 3, 3" size="1296"/>
			<output>
				<port id="0" precision="FP16">
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="152" name="Reshape_1714" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="153" name="GroupConvolution_1780" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="2, 2"/>
			<rt_info>
				<attribute name="fused_names" value="GroupConvolution_1780, Reshape_1714" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>129</dim>
					<dim>257</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="154" name="Reshape_1800_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="6220" shape="1, 72, 1, 1" size="144"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="155" name="Reshape_1800" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="156" name="input.51" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_1799, Reshape_1800, input.51" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.51" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="157" name="onnx::Conv_481" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_481" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_481" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="158" name="onnx::Conv_836_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="6364" shape="24, 72, 1, 1" size="3456"/>
			<output>
				<port id="0" precision="FP16">
					<dim>24</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="159" name="onnx::Conv_836" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_836" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>24</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_836" precision="FP32">
					<dim>24</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="160" name="Convolution_1829" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_1829" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>24</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="161" name="Reshape_1849_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="9820" shape="1, 24, 1, 1" size="48"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="162" name="Reshape_1849" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="163" name="input.59" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_1848, Reshape_1849, input.59" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.59" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="164" name="onnx::Conv_839_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="9868" shape="88, 24, 1, 1" size="4224"/>
			<output>
				<port id="0" precision="FP16">
					<dim>88</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="165" name="onnx::Conv_839" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_839" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>88</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_839" precision="FP32">
					<dim>88</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="166" name="Convolution_1877" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_1877" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>88</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>88</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="167" name="Reshape_1897_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="14092" shape="1, 88, 1, 1" size="176"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>88</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="168" name="Reshape_1897" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>88</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>88</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="169" name="input.67" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_1896, Reshape_1897, input.67" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>88</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>88</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.67" precision="FP32">
					<dim>1</dim>
					<dim>88</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="170" name="onnx::Conv_486" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_486" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>88</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_486" precision="FP32">
					<dim>1</dim>
					<dim>88</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="171" name="Reshape_1933_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="14268" shape="88, 1, 1, 3, 3" size="1584"/>
			<output>
				<port id="0" precision="FP16">
					<dim>88</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="172" name="Reshape_1933" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>88</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>88</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="173" name="GroupConvolution_1999" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="1, 1" pads_end="1, 1" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="GroupConvolution_1999, Reshape_1933" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>88</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>88</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>88</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="174" name="Reshape_2019_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="15852" shape="1, 88, 1, 1" size="176"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>88</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="175" name="Reshape_2019" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>88</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>88</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="176" name="input.75" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_2018, Reshape_2019, input.75" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>88</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>88</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.75" precision="FP32">
					<dim>1</dim>
					<dim>88</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="177" name="onnx::Conv_489" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_489" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>88</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_489" precision="FP32">
					<dim>1</dim>
					<dim>88</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="178" name="onnx::Conv_845_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="16028" shape="24, 88, 1, 1" size="4224"/>
			<output>
				<port id="0" precision="FP16">
					<dim>24</dim>
					<dim>88</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="179" name="onnx::Conv_845" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_845" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>24</dim>
					<dim>88</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_845" precision="FP32">
					<dim>24</dim>
					<dim>88</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="180" name="Convolution_2048" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_2048" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>88</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>24</dim>
					<dim>88</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="181" name="Reshape_2068_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="20252" shape="1, 24, 1, 1" size="48"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="182" name="Reshape_2068" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="183" name="onnx::Add_844" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_2067, Reshape_2068, onnx::Add_844" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Add_844" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="184" name="onnx::Conv_492" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_492" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Conv_492" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="185" name="onnx::Conv_848_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="20300" shape="96, 24, 1, 1" size="4608"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="186" name="onnx::Conv_848" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_848" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_848" precision="FP32">
					<dim>96</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="187" name="Convolution_2097" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_2097" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>96</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="188" name="Reshape_2117_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="24908" shape="1, 96, 1, 1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="189" name="Reshape_2117" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="190" name="input.87" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_2116, Reshape_2117, input.87" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.87" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="191" name="Constant_2145_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="192" name="Constant_2145" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_2145" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="193" name="Constant_2146_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="194" name="Constant_2146" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_2146" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="195" name="onnx::Mul_495" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_495" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_495" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="196" name="onnx::Shape_496" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Shape_496" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Shape_496" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="197" name="onnx::Sub_505" type="Const" version="opset1">
			<data element_type="i64" offset="25100" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Sub_505" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Sub_505" precision="I64"/>
			</output>
		</layer>
		<layer id="198" name="onnx::Gather_500" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Gather_497, onnx::Gather_500" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Gather_497,onnx::Gather_500" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="199" name="onnx::Gather_501" type="Const" version="opset1">
			<data element_type="i64" offset="914" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Gather_501" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Gather_501" precision="I64"/>
			</output>
		</layer>
		<layer id="200" name="Constant_2155" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_2155" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="201" name="onnx::Sub_502" type="Gather" version="opset8">
			<data batch_dims="0"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_2155, onnx::Gather_501, onnx::Sub_502" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
				<port id="1" precision="I64"/>
				<port id="2" precision="I64"/>
			</input>
			<output>
				<port id="3" names="onnx::Sub_502" precision="I64"/>
			</output>
		</layer>
		<layer id="202" name="onnx::Div_506" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_506, onnx::Sub_505" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Div_506" precision="I64"/>
			</output>
		</layer>
		<layer id="203" name="onnx::Div_507" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_507" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Div_507" precision="I64"/>
			</output>
		</layer>
		<layer id="204" name="onnx::Cast_508" type="Divide" version="opset1">
			<data auto_broadcast="numpy" m_pythondiv="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_508, onnx::Cast_509, onnx::Div_507, onnx::Unsqueeze_510" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Cast_508,onnx::Cast_509,onnx::Unsqueeze_510" precision="I64"/>
			</output>
		</layer>
		<layer id="205" name="Constant_2188" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_2188" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="206" name="onnx::Concat_530" type="Unsqueeze" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_2188, onnx::Concat_530" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Concat_530" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="207" name="onnx::Div_511" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_511" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Div_511" precision="I64"/>
			</output>
		</layer>
		<layer id="208" name="onnx::Cast_512" type="Divide" version="opset1">
			<data auto_broadcast="numpy" m_pythondiv="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_512, onnx::Cast_513, onnx::Div_511, onnx::Sub_514" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Cast_512,onnx::Cast_513,onnx::Sub_514" precision="I64"/>
			</output>
		</layer>
		<layer id="209" name="onnx::Unsqueeze_515" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Unsqueeze_515" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Unsqueeze_515" precision="I64"/>
			</output>
		</layer>
		<layer id="210" name="Constant_2190" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_2190" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="211" name="onnx::Concat_531" type="Unsqueeze" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_2190, onnx::Concat_531" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Concat_531" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="212" name="onnx::Sub_503" type="Const" version="opset1">
			<data element_type="i64" offset="25108" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Sub_503" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Sub_503" precision="I64"/>
			</output>
		</layer>
		<layer id="213" name="onnx::Gather_498" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Gather_498" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Gather_498" precision="I64"/>
			</output>
		</layer>
		<layer id="214" name="Constant_2151" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_2151" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="215" name="onnx::Sub_499" type="Gather" version="opset8">
			<data batch_dims="0"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_2151, onnx::Gather_498, onnx::Sub_499" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
				<port id="1" precision="I64"/>
				<port id="2" precision="I64"/>
			</input>
			<output>
				<port id="3" names="onnx::Sub_499" precision="I64"/>
			</output>
		</layer>
		<layer id="216" name="onnx::Div_504" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_504, onnx::Sub_503" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Div_504" precision="I64"/>
			</output>
		</layer>
		<layer id="217" name="onnx::Div_516" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_516" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Div_516" precision="I64"/>
			</output>
		</layer>
		<layer id="218" name="onnx::Cast_517" type="Divide" version="opset1">
			<data auto_broadcast="numpy" m_pythondiv="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_517, onnx::Cast_518, onnx::Div_516, onnx::Unsqueeze_519" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Cast_517,onnx::Cast_518,onnx::Unsqueeze_519" precision="I64"/>
			</output>
		</layer>
		<layer id="219" name="Constant_2192" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_2192" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="220" name="onnx::Concat_532" type="Unsqueeze" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_2192, onnx::Concat_532" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Concat_532" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="221" name="onnx::Div_520" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_520" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Div_520" precision="I64"/>
			</output>
		</layer>
		<layer id="222" name="onnx::Cast_521" type="Divide" version="opset1">
			<data auto_broadcast="numpy" m_pythondiv="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_521, onnx::Cast_522, onnx::Div_520, onnx::Sub_523" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Cast_521,onnx::Cast_522,onnx::Sub_523" precision="I64"/>
			</output>
		</layer>
		<layer id="223" name="onnx::Unsqueeze_524" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Unsqueeze_524" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Unsqueeze_524" precision="I64"/>
			</output>
		</layer>
		<layer id="224" name="Constant_2194" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_2194" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="225" name="onnx::Concat_533" type="Unsqueeze" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_2194, onnx::Concat_533" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Concat_533" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="226" name="onnx::Cast_534" type="Concat" version="opset1">
			<data axis="0"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_534, onnx::Concat_542" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
				<port id="2" precision="I64">
					<dim>1</dim>
				</port>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="4" names="onnx::Cast_534,onnx::Concat_542" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="227" name="onnx::Concat_543" type="Const" version="opset1">
			<data element_type="i64" offset="946" shape="4" size="32"/>
			<output>
				<port id="0" names="onnx::Concat_543" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="228" name="onnx::Reshape_544" type="Concat" version="opset1">
			<data axis="0"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Concat_543, onnx::ConstantOfShape_541, onnx::Gather_536, onnx::Reshape_544, onnx::Sub_537, onnx::Sub_540" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Reshape_544" precision="I64">
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="229" name="onnx::Reshape_545" type="Const" version="opset1">
			<data element_type="i64" offset="978" shape="2" size="16"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Reshape_545" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Reshape_545" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="230" name="onnx::Slice_546" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Reshape_545, onnx::Slice_546" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>8</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Slice_546" precision="I64">
					<dim>4</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="231" name="onnx::Slice_548" type="Const" version="opset1">
			<data element_type="i64" offset="994" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Slice_547, onnx::Slice_548, onnx::Slice_549, onnx::Slice_550, onnx::Transpose_551" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Slice_548" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="232" name="onnx::Slice_549" type="Const" version="opset1">
			<data element_type="i64" offset="1002" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Slice_547, onnx::Slice_548, onnx::Slice_549, onnx::Slice_550, onnx::Transpose_551" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Slice_549" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="233" name="onnx::Slice_550" type="Const" version="opset1">
			<data element_type="i64" offset="994" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Slice_547, onnx::Slice_548, onnx::Slice_549, onnx::Slice_550, onnx::Transpose_551" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Slice_550" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="234" name="onnx::Transpose_551" type="StridedSlice" version="opset1">
			<data begin_mask="0" ellipsis_mask="" end_mask="0" new_axis_mask="" shrink_axis_mask=""/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Slice_547, onnx::Slice_548, onnx::Slice_549, onnx::Slice_550, onnx::Transpose_551" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
					<dim>2</dim>
				</port>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
				<port id="2" precision="I64">
					<dim>1</dim>
				</port>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="4" names="onnx::Transpose_551" precision="I64">
					<dim>4</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="235" name="Constant_2248" type="Const" version="opset1">
			<data element_type="i64" offset="1010" shape="2" size="16"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_2248" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="236" name="onnx::Reshape_552" type="Transpose" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_2248, onnx::Reshape_552" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
					<dim>2</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Reshape_552" precision="I64">
					<dim>2</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="237" name="onnx::Reshape_553" type="Const" version="opset1">
			<data element_type="i64" offset="994" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Reshape_553" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Reshape_553" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="238" name="onnx::Cast_554" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_554, onnx::Pad_555, onnx::Reshape_553" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>2</dim>
					<dim>4</dim>
				</port>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Cast_554,onnx::Pad_555" precision="I64">
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="239" name="Constant_2259" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_2259" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="240" name="Split_2260" type="Split" version="opset1">
			<data num_splits="2"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_2259, Split_2260" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>8</dim>
				</port>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" precision="I64">
					<dim>4</dim>
				</port>
				<port id="3" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="241" name="onnx::Pad_556_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1026" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="242" name="onnx::Pad_556" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Pad_556" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" names="onnx::Pad_556" precision="FP32"/>
			</output>
		</layer>
		<layer id="243" name="onnx::Conv_557" type="Pad" version="opset1">
			<data pad_mode="constant"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_557" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>64</dim>
					<dim>128</dim>
				</port>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
				<port id="2" precision="I64">
					<dim>4</dim>
				</port>
				<port id="3" precision="FP32"/>
			</input>
			<output>
				<port id="4" names="onnx::Conv_557" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>67</dim>
					<dim>131</dim>
				</port>
			</output>
		</layer>
		<layer id="244" name="Reshape_2649_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="25116" shape="96, 1, 1, 5, 5" size="4800"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="245" name="Reshape_2649" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="246" name="GroupConvolution_2715" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="2, 2"/>
			<rt_info>
				<attribute name="fused_names" value="GroupConvolution_2715, Reshape_2649" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>67</dim>
					<dim>131</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="247" name="Reshape_2735_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="29916" shape="1, 96, 1, 1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="248" name="Reshape_2735" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="249" name="input.95" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_2734, Reshape_2735, input.95" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.95" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="250" name="Constant_2763_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="251" name="Constant_2763" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_2763" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="252" name="Constant_2764_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="253" name="Constant_2764" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_2764" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="254" name="onnx::Mul_560" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_560" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_560" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="255" name="onnx::ReduceMean_561" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::ReduceMean_561" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::ReduceMean_561" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="256" name="Constant_2767" type="Const" version="opset1">
			<data element_type="i64" offset="1348" shape="2" size="16"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_2767" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="257" name="input.99" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<rt_info>
				<attribute name="fused_names" value="input.99" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.99" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="258" name="encoder.model.blocks.2.0.se.conv_reduce.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="30108" shape="24, 96, 1, 1" size="4608"/>
			<output>
				<port id="0" precision="FP16">
					<dim>24</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="259" name="encoder.model.blocks.2.0.se.conv_reduce.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="encoder.model.blocks.2.0.se.conv_reduce.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>24</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="encoder.model.blocks.2.0.se.conv_reduce.weight" precision="FP32">
					<dim>24</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="260" name="Convolution_2769" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_2769" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>24</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="261" name="Reshape_2789_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="34716" shape="1, 24, 1, 1" size="48"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="262" name="Reshape_2789" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="263" name="input.103" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_2788, Reshape_2789, input.103" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.103" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="264" name="onnx::Conv_564" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_564" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_564" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="265" name="encoder.model.blocks.2.0.se.conv_expand.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="34764" shape="96, 24, 1, 1" size="4608"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="266" name="encoder.model.blocks.2.0.se.conv_expand.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="encoder.model.blocks.2.0.se.conv_expand.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="encoder.model.blocks.2.0.se.conv_expand.weight" precision="FP32">
					<dim>96</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="267" name="Convolution_2818" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_2818" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>96</dim>
					<dim>24</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="268" name="Reshape_2838_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="39372" shape="1, 96, 1, 1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="269" name="Reshape_2838" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="270" name="input.107" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_2837, Reshape_2838, input.107" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.107" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="271" name="Constant_2866_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="272" name="Constant_2866" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_2866" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="273" name="Constant_2867_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="274" name="Constant_2867" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_2867" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="275" name="onnx::Mul_566" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_566" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_566" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="276" name="input.111" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="input.111" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.111" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="277" name="onnx::Conv_854_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="39564" shape="40, 96, 1, 1" size="7680"/>
			<output>
				<port id="0" precision="FP16">
					<dim>40</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="278" name="onnx::Conv_854" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_854" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>40</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_854" precision="FP32">
					<dim>40</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="279" name="Convolution_2870" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_2870" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>40</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="280" name="Reshape_2890_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="47244" shape="1, 40, 1, 1" size="80"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="281" name="Reshape_2890" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="282" name="input.119" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_2889, Reshape_2890, input.119" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.119" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="283" name="onnx::Conv_857_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="47324" shape="240, 40, 1, 1" size="19200"/>
			<output>
				<port id="0" precision="FP16">
					<dim>240</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="284" name="onnx::Conv_857" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_857" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>240</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_857" precision="FP32">
					<dim>240</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="285" name="Convolution_2918" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_2918" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>240</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="286" name="Reshape_2938_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="66524" shape="1, 240, 1, 1" size="480"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="287" name="Reshape_2938" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="288" name="input.127" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_2937, Reshape_2938, input.127" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.127" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="289" name="Constant_2966_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="290" name="Constant_2966" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_2966" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="291" name="Constant_2967_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="292" name="Constant_2967" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_2967" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="293" name="onnx::Mul_572" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_572" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_572" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="294" name="onnx::Conv_573" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_573" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Conv_573" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="295" name="Reshape_2977_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="67004" shape="240, 1, 1, 5, 5" size="12000"/>
			<output>
				<port id="0" precision="FP16">
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="296" name="Reshape_2977" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="297" name="GroupConvolution_3043" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="2, 2" pads_end="2, 2" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="GroupConvolution_3043, Reshape_2977" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="298" name="Reshape_3063_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="79004" shape="1, 240, 1, 1" size="480"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="299" name="Reshape_3063" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="300" name="input.135" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_3062, Reshape_3063, input.135" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.135" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="301" name="Constant_3091_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="302" name="Constant_3091" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_3091" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="303" name="Constant_3092_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="304" name="Constant_3092" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_3092" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="305" name="onnx::Mul_576" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_576" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_576" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="306" name="onnx::ReduceMean_577" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::ReduceMean_577" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::ReduceMean_577" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="307" name="Constant_3095" type="Const" version="opset1">
			<data element_type="i64" offset="1348" shape="2" size="16"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_3095" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="308" name="input.139" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<rt_info>
				<attribute name="fused_names" value="input.139" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.139" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="309" name="encoder.model.blocks.2.1.se.conv_reduce.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="79484" shape="64, 240, 1, 1" size="30720"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="310" name="encoder.model.blocks.2.1.se.conv_reduce.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="encoder.model.blocks.2.1.se.conv_reduce.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="encoder.model.blocks.2.1.se.conv_reduce.weight" precision="FP32">
					<dim>64</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="311" name="Convolution_3097" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_3097" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>64</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="312" name="Reshape_3117_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="110204" shape="1, 64, 1, 1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="313" name="Reshape_3117" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="314" name="input.143" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_3116, Reshape_3117, input.143" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.143" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="315" name="onnx::Conv_580" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_580" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_580" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="316" name="encoder.model.blocks.2.1.se.conv_expand.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="110332" shape="240, 64, 1, 1" size="30720"/>
			<output>
				<port id="0" precision="FP16">
					<dim>240</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="317" name="encoder.model.blocks.2.1.se.conv_expand.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="encoder.model.blocks.2.1.se.conv_expand.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>240</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="encoder.model.blocks.2.1.se.conv_expand.weight" precision="FP32">
					<dim>240</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="318" name="Convolution_3146" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_3146" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>240</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="319" name="Reshape_3166_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="141052" shape="1, 240, 1, 1" size="480"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="320" name="Reshape_3166" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="321" name="input.147" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_3165, Reshape_3166, input.147" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.147" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="322" name="Constant_3194_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="323" name="Constant_3194" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_3194" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="324" name="Constant_3195_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="325" name="Constant_3195" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_3195" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="326" name="onnx::Mul_582" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_582" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_582" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="327" name="input.151" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="input.151" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.151" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="328" name="onnx::Conv_863_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="141532" shape="40, 240, 1, 1" size="19200"/>
			<output>
				<port id="0" precision="FP16">
					<dim>40</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="329" name="onnx::Conv_863" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_863" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>40</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_863" precision="FP32">
					<dim>40</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="330" name="Convolution_3198" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_3198" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>40</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="331" name="Reshape_3218_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="160732" shape="1, 40, 1, 1" size="80"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="332" name="Reshape_3218" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="333" name="onnx::Add_862" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_3217, Reshape_3218, onnx::Add_862" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Add_862" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="334" name="onnx::Conv_586" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_586" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Conv_586" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="335" name="onnx::Conv_866_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="160812" shape="240, 40, 1, 1" size="19200"/>
			<output>
				<port id="0" precision="FP16">
					<dim>240</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="336" name="onnx::Conv_866" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_866" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>240</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_866" precision="FP32">
					<dim>240</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="337" name="Convolution_3247" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_3247" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>240</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="338" name="Reshape_3267_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="180012" shape="1, 240, 1, 1" size="480"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="339" name="Reshape_3267" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="340" name="input.163" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_3266, Reshape_3267, input.163" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.163" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="341" name="Constant_3295_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="342" name="Constant_3295" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_3295" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="343" name="Constant_3296_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="344" name="Constant_3296" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_3296" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="345" name="onnx::Mul_589" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_589" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_589" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="346" name="onnx::Conv_590" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_590" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Conv_590" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="347" name="Reshape_3306_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="180492" shape="240, 1, 1, 5, 5" size="12000"/>
			<output>
				<port id="0" precision="FP16">
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="348" name="Reshape_3306" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="349" name="GroupConvolution_3372" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="2, 2" pads_end="2, 2" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="GroupConvolution_3372, Reshape_3306" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="350" name="Reshape_3392_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="192492" shape="1, 240, 1, 1" size="480"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="351" name="Reshape_3392" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="352" name="input.171" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_3391, Reshape_3392, input.171" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.171" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="353" name="Constant_3420_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="354" name="Constant_3420" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_3420" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="355" name="Constant_3421_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="356" name="Constant_3421" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_3421" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="357" name="onnx::Mul_593" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_593" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_593" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="358" name="onnx::ReduceMean_594" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::ReduceMean_594" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::ReduceMean_594" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="359" name="Constant_3424" type="Const" version="opset1">
			<data element_type="i64" offset="1348" shape="2" size="16"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_3424" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="360" name="input.175" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<rt_info>
				<attribute name="fused_names" value="input.175" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.175" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="361" name="encoder.model.blocks.2.2.se.conv_reduce.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="192972" shape="64, 240, 1, 1" size="30720"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="362" name="encoder.model.blocks.2.2.se.conv_reduce.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="encoder.model.blocks.2.2.se.conv_reduce.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="encoder.model.blocks.2.2.se.conv_reduce.weight" precision="FP32">
					<dim>64</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="363" name="Convolution_3426" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_3426" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>64</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="364" name="Reshape_3446_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="223692" shape="1, 64, 1, 1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="365" name="Reshape_3446" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="366" name="input.179" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_3445, Reshape_3446, input.179" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.179" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="367" name="onnx::Conv_597" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_597" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_597" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="368" name="encoder.model.blocks.2.2.se.conv_expand.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="223820" shape="240, 64, 1, 1" size="30720"/>
			<output>
				<port id="0" precision="FP16">
					<dim>240</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="369" name="encoder.model.blocks.2.2.se.conv_expand.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="encoder.model.blocks.2.2.se.conv_expand.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>240</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="encoder.model.blocks.2.2.se.conv_expand.weight" precision="FP32">
					<dim>240</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="370" name="Convolution_3475" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_3475" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>240</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="371" name="Reshape_3495_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="254540" shape="1, 240, 1, 1" size="480"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="372" name="Reshape_3495" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="373" name="input.183" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_3494, Reshape_3495, input.183" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.183" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="374" name="Constant_3523_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="375" name="Constant_3523" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_3523" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="376" name="Constant_3524_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="377" name="Constant_3524" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_3524" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="378" name="onnx::Mul_599" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_599" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_599" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="379" name="input.187" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="input.187" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.187" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="380" name="onnx::Conv_872_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="255020" shape="40, 240, 1, 1" size="19200"/>
			<output>
				<port id="0" precision="FP16">
					<dim>40</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="381" name="onnx::Conv_872" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_872" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>40</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_872" precision="FP32">
					<dim>40</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="382" name="Convolution_3527" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_3527" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>240</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>40</dim>
					<dim>240</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="383" name="Reshape_3547_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="274220" shape="1, 40, 1, 1" size="80"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="384" name="Reshape_3547" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="385" name="onnx::Add_871" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_3546, Reshape_3547, onnx::Add_871" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Add_871" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="386" name="onnx::Conv_603" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_603" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Conv_603" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="387" name="onnx::Conv_875_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="274300" shape="120, 40, 1, 1" size="9600"/>
			<output>
				<port id="0" precision="FP16">
					<dim>120</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="388" name="onnx::Conv_875" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_875" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>120</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_875" precision="FP32">
					<dim>120</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="389" name="Convolution_3576" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_3576" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>120</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="390" name="Reshape_3596_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="283900" shape="1, 120, 1, 1" size="240"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="391" name="Reshape_3596" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="392" name="input.199" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_3595, Reshape_3596, input.199" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.199" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="393" name="Constant_3624_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="394" name="Constant_3624" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_3624" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="395" name="Constant_3625_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="396" name="Constant_3625" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_3625" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="397" name="onnx::Mul_606" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_606" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_606" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="398" name="onnx::Conv_607" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_607" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Conv_607" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="399" name="Reshape_3635_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="284140" shape="120, 1, 1, 5, 5" size="6000"/>
			<output>
				<port id="0" precision="FP16">
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="400" name="Reshape_3635" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="401" name="GroupConvolution_3701" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="2, 2" pads_end="2, 2" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="GroupConvolution_3701, Reshape_3635" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="402" name="Reshape_3721_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="290140" shape="1, 120, 1, 1" size="240"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="403" name="Reshape_3721" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="404" name="input.207" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_3720, Reshape_3721, input.207" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.207" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="405" name="Constant_3749_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="406" name="Constant_3749" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_3749" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="407" name="Constant_3750_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="408" name="Constant_3750" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_3750" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="409" name="onnx::Mul_610" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_610" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_610" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="410" name="onnx::ReduceMean_611" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::ReduceMean_611" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::ReduceMean_611" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="411" name="Constant_3753" type="Const" version="opset1">
			<data element_type="i64" offset="1348" shape="2" size="16"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_3753" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="412" name="input.211" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<rt_info>
				<attribute name="fused_names" value="input.211" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.211" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="413" name="encoder.model.blocks.3.0.se.conv_reduce.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="290380" shape="32, 120, 1, 1" size="7680"/>
			<output>
				<port id="0" precision="FP16">
					<dim>32</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="414" name="encoder.model.blocks.3.0.se.conv_reduce.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="encoder.model.blocks.3.0.se.conv_reduce.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>32</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="encoder.model.blocks.3.0.se.conv_reduce.weight" precision="FP32">
					<dim>32</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="415" name="Convolution_3755" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_3755" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>32</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>32</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="416" name="Reshape_3775_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="298060" shape="1, 32, 1, 1" size="64"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>32</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="417" name="Reshape_3775" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>32</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>32</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="418" name="input.215" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_3774, Reshape_3775, input.215" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>32</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>32</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.215" precision="FP32">
					<dim>1</dim>
					<dim>32</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="419" name="onnx::Conv_614" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_614" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>32</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_614" precision="FP32">
					<dim>1</dim>
					<dim>32</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="420" name="encoder.model.blocks.3.0.se.conv_expand.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="298124" shape="120, 32, 1, 1" size="7680"/>
			<output>
				<port id="0" precision="FP16">
					<dim>120</dim>
					<dim>32</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="421" name="encoder.model.blocks.3.0.se.conv_expand.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="encoder.model.blocks.3.0.se.conv_expand.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>120</dim>
					<dim>32</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="encoder.model.blocks.3.0.se.conv_expand.weight" precision="FP32">
					<dim>120</dim>
					<dim>32</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="422" name="Convolution_3804" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_3804" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>32</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>120</dim>
					<dim>32</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="423" name="Reshape_3824_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="305804" shape="1, 120, 1, 1" size="240"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="424" name="Reshape_3824" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="425" name="input.219" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_3823, Reshape_3824, input.219" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.219" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="426" name="Constant_3852_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="427" name="Constant_3852" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_3852" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="428" name="Constant_3853_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="429" name="Constant_3853" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_3853" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="430" name="onnx::Mul_616" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_616" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_616" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="431" name="input.223" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="input.223" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.223" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="432" name="onnx::Conv_881_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="306044" shape="48, 120, 1, 1" size="11520"/>
			<output>
				<port id="0" precision="FP16">
					<dim>48</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="433" name="onnx::Conv_881" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_881" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>48</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_881" precision="FP32">
					<dim>48</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="434" name="Convolution_3856" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_3856" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>120</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>48</dim>
					<dim>120</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="435" name="Reshape_3876_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="317564" shape="1, 48, 1, 1" size="96"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="436" name="Reshape_3876" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="437" name="input.231" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_3875, Reshape_3876, input.231" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.231" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="438" name="onnx::Conv_884_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="317660" shape="144, 48, 1, 1" size="13824"/>
			<output>
				<port id="0" precision="FP16">
					<dim>144</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="439" name="onnx::Conv_884" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_884" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>144</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_884" precision="FP32">
					<dim>144</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="440" name="Convolution_3904" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_3904" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>144</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="441" name="Reshape_3924_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="331484" shape="1, 144, 1, 1" size="288"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="442" name="Reshape_3924" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="443" name="input.239" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_3923, Reshape_3924, input.239" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.239" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="444" name="Constant_3952_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="445" name="Constant_3952" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_3952" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="446" name="Constant_3953_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="447" name="Constant_3953" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_3953" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="448" name="onnx::Mul_622" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_622" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_622" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="449" name="onnx::Conv_623" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_623" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Conv_623" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="450" name="Reshape_3963_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="331772" shape="144, 1, 1, 5, 5" size="7200"/>
			<output>
				<port id="0" precision="FP16">
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="451" name="Reshape_3963" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="452" name="GroupConvolution_4029" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="2, 2" pads_end="2, 2" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="GroupConvolution_4029, Reshape_3963" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="453" name="Reshape_4049_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="338972" shape="1, 144, 1, 1" size="288"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="454" name="Reshape_4049" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="455" name="input.247" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_4048, Reshape_4049, input.247" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.247" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="456" name="Constant_4077_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="457" name="Constant_4077" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_4077" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="458" name="Constant_4078_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="459" name="Constant_4078" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_4078" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="460" name="onnx::Mul_626" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_626" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_626" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="461" name="onnx::ReduceMean_627" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::ReduceMean_627" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::ReduceMean_627" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="462" name="Constant_4081" type="Const" version="opset1">
			<data element_type="i64" offset="1348" shape="2" size="16"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_4081" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="463" name="input.251" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<rt_info>
				<attribute name="fused_names" value="input.251" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.251" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="464" name="encoder.model.blocks.3.1.se.conv_reduce.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="339260" shape="40, 144, 1, 1" size="11520"/>
			<output>
				<port id="0" precision="FP16">
					<dim>40</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="465" name="encoder.model.blocks.3.1.se.conv_reduce.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="encoder.model.blocks.3.1.se.conv_reduce.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>40</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="encoder.model.blocks.3.1.se.conv_reduce.weight" precision="FP32">
					<dim>40</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="466" name="Convolution_4083" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_4083" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>40</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="467" name="Reshape_4103_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="350780" shape="1, 40, 1, 1" size="80"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="468" name="Reshape_4103" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="469" name="input.255" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_4102, Reshape_4103, input.255" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.255" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="470" name="onnx::Conv_630" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_630" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_630" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="471" name="encoder.model.blocks.3.1.se.conv_expand.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="350860" shape="144, 40, 1, 1" size="11520"/>
			<output>
				<port id="0" precision="FP16">
					<dim>144</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="472" name="encoder.model.blocks.3.1.se.conv_expand.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="encoder.model.blocks.3.1.se.conv_expand.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>144</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="encoder.model.blocks.3.1.se.conv_expand.weight" precision="FP32">
					<dim>144</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="473" name="Convolution_4132" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_4132" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>144</dim>
					<dim>40</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="474" name="Reshape_4152_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="362380" shape="1, 144, 1, 1" size="288"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="475" name="Reshape_4152" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="476" name="input.259" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_4151, Reshape_4152, input.259" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.259" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="477" name="Constant_4180_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="478" name="Constant_4180" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_4180" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="479" name="Constant_4181_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="480" name="Constant_4181" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_4181" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="481" name="onnx::Mul_632" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_632" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_632" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="482" name="input.263" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="input.263" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.263" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="483" name="onnx::Conv_890_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="362668" shape="48, 144, 1, 1" size="13824"/>
			<output>
				<port id="0" precision="FP16">
					<dim>48</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="484" name="onnx::Conv_890" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_890" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>48</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_890" precision="FP32">
					<dim>48</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="485" name="Convolution_4184" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_4184" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>48</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="486" name="Reshape_4204_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="376492" shape="1, 48, 1, 1" size="96"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="487" name="Reshape_4204" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="488" name="onnx::Add_889" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_4203, Reshape_4204, onnx::Add_889" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Add_889" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="489" name="onnx::Conv_636" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_636" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Conv_636" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="490" name="onnx::Conv_893_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="376588" shape="288, 48, 1, 1" size="27648"/>
			<output>
				<port id="0" precision="FP16">
					<dim>288</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="491" name="onnx::Conv_893" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_893" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>288</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_893" precision="FP32">
					<dim>288</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="492" name="Convolution_4233" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="2, 2" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_4233" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>288</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="493" name="Reshape_4253_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="404236" shape="1, 288, 1, 1" size="576"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="494" name="Reshape_4253" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="495" name="input.275" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_4252, Reshape_4253, input.275" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.275" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="496" name="Constant_4281_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="497" name="Constant_4281" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_4281" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="498" name="Constant_4282_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="499" name="Constant_4282" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_4282" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="500" name="onnx::Mul_639" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_639" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_639" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="501" name="onnx::Shape_640" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Shape_640" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Shape_640" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="502" name="onnx::Sub_649" type="Const" version="opset1">
			<data element_type="i64" offset="404812" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Sub_649" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Sub_649" precision="I64"/>
			</output>
		</layer>
		<layer id="503" name="onnx::Gather_644" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Gather_641, onnx::Gather_644" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Gather_641,onnx::Gather_644" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="504" name="onnx::Gather_645" type="Const" version="opset1">
			<data element_type="i64" offset="914" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Gather_645" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Gather_645" precision="I64"/>
			</output>
		</layer>
		<layer id="505" name="Constant_4291" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_4291" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="506" name="onnx::Sub_646" type="Gather" version="opset8">
			<data batch_dims="0"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_4291, onnx::Gather_645, onnx::Sub_646" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
				<port id="1" precision="I64"/>
				<port id="2" precision="I64"/>
			</input>
			<output>
				<port id="3" names="onnx::Sub_646" precision="I64"/>
			</output>
		</layer>
		<layer id="507" name="onnx::Div_650" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_650, onnx::Sub_649" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Div_650" precision="I64"/>
			</output>
		</layer>
		<layer id="508" name="onnx::Div_651" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_651" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Div_651" precision="I64"/>
			</output>
		</layer>
		<layer id="509" name="onnx::Cast_652" type="Divide" version="opset1">
			<data auto_broadcast="numpy" m_pythondiv="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_652, onnx::Cast_653, onnx::Div_651, onnx::Unsqueeze_654" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Cast_652,onnx::Cast_653,onnx::Unsqueeze_654" precision="I64"/>
			</output>
		</layer>
		<layer id="510" name="Constant_4324" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_4324" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="511" name="onnx::Concat_674" type="Unsqueeze" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_4324, onnx::Concat_674" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Concat_674" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="512" name="onnx::Div_655" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_655" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Div_655" precision="I64"/>
			</output>
		</layer>
		<layer id="513" name="onnx::Cast_656" type="Divide" version="opset1">
			<data auto_broadcast="numpy" m_pythondiv="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_656, onnx::Cast_657, onnx::Div_655, onnx::Sub_658" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Cast_656,onnx::Cast_657,onnx::Sub_658" precision="I64"/>
			</output>
		</layer>
		<layer id="514" name="onnx::Unsqueeze_659" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Unsqueeze_659" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Unsqueeze_659" precision="I64"/>
			</output>
		</layer>
		<layer id="515" name="Constant_4326" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_4326" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="516" name="onnx::Concat_675" type="Unsqueeze" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_4326, onnx::Concat_675" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Concat_675" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="517" name="onnx::Sub_647" type="Const" version="opset1">
			<data element_type="i64" offset="404820" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Sub_647" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Sub_647" precision="I64"/>
			</output>
		</layer>
		<layer id="518" name="onnx::Gather_642" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Gather_642" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Gather_642" precision="I64"/>
			</output>
		</layer>
		<layer id="519" name="Constant_4287" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_4287" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="520" name="onnx::Sub_643" type="Gather" version="opset8">
			<data batch_dims="0"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_4287, onnx::Gather_642, onnx::Sub_643" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
				<port id="1" precision="I64"/>
				<port id="2" precision="I64"/>
			</input>
			<output>
				<port id="3" names="onnx::Sub_643" precision="I64"/>
			</output>
		</layer>
		<layer id="521" name="onnx::Div_648" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_648, onnx::Sub_647" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Div_648" precision="I64"/>
			</output>
		</layer>
		<layer id="522" name="onnx::Div_660" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_660" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Div_660" precision="I64"/>
			</output>
		</layer>
		<layer id="523" name="onnx::Cast_661" type="Divide" version="opset1">
			<data auto_broadcast="numpy" m_pythondiv="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_661, onnx::Cast_662, onnx::Div_660, onnx::Unsqueeze_663" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Cast_661,onnx::Cast_662,onnx::Unsqueeze_663" precision="I64"/>
			</output>
		</layer>
		<layer id="524" name="Constant_4328" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_4328" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="525" name="onnx::Concat_676" type="Unsqueeze" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_4328, onnx::Concat_676" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Concat_676" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="526" name="onnx::Div_664" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Div_664" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Div_664" precision="I64"/>
			</output>
		</layer>
		<layer id="527" name="onnx::Cast_665" type="Divide" version="opset1">
			<data auto_broadcast="numpy" m_pythondiv="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_665, onnx::Cast_666, onnx::Div_664, onnx::Sub_667" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Cast_665,onnx::Cast_666,onnx::Sub_667" precision="I64"/>
			</output>
		</layer>
		<layer id="528" name="onnx::Unsqueeze_668" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Unsqueeze_668" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" names="onnx::Unsqueeze_668" precision="I64"/>
			</output>
		</layer>
		<layer id="529" name="Constant_4330" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_4330" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="530" name="onnx::Concat_677" type="Unsqueeze" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_4330, onnx::Concat_677" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64"/>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Concat_677" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="531" name="onnx::Cast_678" type="Concat" version="opset1">
			<data axis="0"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_678, onnx::Concat_686" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
				<port id="2" precision="I64">
					<dim>1</dim>
				</port>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="4" names="onnx::Cast_678,onnx::Concat_686" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="532" name="onnx::Concat_687" type="Const" version="opset1">
			<data element_type="i64" offset="946" shape="4" size="32"/>
			<output>
				<port id="0" names="onnx::Concat_687" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="533" name="onnx::Reshape_688" type="Concat" version="opset1">
			<data axis="0"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Concat_687, onnx::ConstantOfShape_685, onnx::Gather_680, onnx::Reshape_688, onnx::Sub_681, onnx::Sub_684" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Reshape_688" precision="I64">
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="534" name="onnx::Reshape_689" type="Const" version="opset1">
			<data element_type="i64" offset="978" shape="2" size="16"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Reshape_689" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Reshape_689" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="535" name="onnx::Slice_690" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Reshape_689, onnx::Slice_690" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>8</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Slice_690" precision="I64">
					<dim>4</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="536" name="onnx::Slice_692" type="Const" version="opset1">
			<data element_type="i64" offset="994" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Slice_691, onnx::Slice_692, onnx::Slice_693, onnx::Slice_694, onnx::Transpose_695" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Slice_692" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="537" name="onnx::Slice_693" type="Const" version="opset1">
			<data element_type="i64" offset="1002" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Slice_691, onnx::Slice_692, onnx::Slice_693, onnx::Slice_694, onnx::Transpose_695" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Slice_693" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="538" name="onnx::Slice_694" type="Const" version="opset1">
			<data element_type="i64" offset="994" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Slice_691, onnx::Slice_692, onnx::Slice_693, onnx::Slice_694, onnx::Transpose_695" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Slice_694" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="539" name="onnx::Transpose_695" type="StridedSlice" version="opset1">
			<data begin_mask="0" ellipsis_mask="" end_mask="0" new_axis_mask="" shrink_axis_mask=""/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Slice_691, onnx::Slice_692, onnx::Slice_693, onnx::Slice_694, onnx::Transpose_695" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
					<dim>2</dim>
				</port>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
				<port id="2" precision="I64">
					<dim>1</dim>
				</port>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="4" names="onnx::Transpose_695" precision="I64">
					<dim>4</dim>
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="540" name="Constant_4384" type="Const" version="opset1">
			<data element_type="i64" offset="1010" shape="2" size="16"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_4384" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="541" name="onnx::Reshape_696" type="Transpose" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="Constant_4384, onnx::Reshape_696" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
					<dim>2</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Reshape_696" precision="I64">
					<dim>2</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="542" name="onnx::Reshape_697" type="Const" version="opset1">
			<data element_type="i64" offset="994" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Reshape_697" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Reshape_697" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="543" name="onnx::Cast_698" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_698, onnx::Pad_699, onnx::Reshape_697" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>2</dim>
					<dim>4</dim>
				</port>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Cast_698,onnx::Pad_699" precision="I64">
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="544" name="Constant_4395" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_4395" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="545" name="Split_4396" type="Split" version="opset1">
			<data num_splits="2"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_4395, Split_4396" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>8</dim>
				</port>
				<port id="1" precision="I64"/>
			</input>
			<output>
				<port id="2" precision="I64">
					<dim>4</dim>
				</port>
				<port id="3" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="546" name="onnx::Pad_700_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1026" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="547" name="onnx::Pad_700" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Pad_700" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" names="onnx::Pad_700" precision="FP32"/>
			</output>
		</layer>
		<layer id="548" name="onnx::Conv_701" type="Pad" version="opset1">
			<data pad_mode="constant"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_701" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
				<port id="2" precision="I64">
					<dim>4</dim>
				</port>
				<port id="3" precision="FP32"/>
			</input>
			<output>
				<port id="4" names="onnx::Conv_701" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>40</dim>
					<dim>72</dim>
				</port>
			</output>
		</layer>
		<layer id="549" name="Reshape_4785_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="404828" shape="288, 1, 1, 5, 5" size="14400"/>
			<output>
				<port id="0" precision="FP16">
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="550" name="Reshape_4785" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="551" name="GroupConvolution_4851" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="2, 2" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="GroupConvolution_4851, Reshape_4785" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>40</dim>
					<dim>72</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="552" name="Reshape_4871_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="419228" shape="1, 288, 1, 1" size="576"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="553" name="Reshape_4871" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="554" name="input.283" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_4870, Reshape_4871, input.283" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.283" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="555" name="Constant_4899_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="556" name="Constant_4899" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_4899" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="557" name="Constant_4900_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="558" name="Constant_4900" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_4900" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="559" name="onnx::Mul_704" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_704" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_704" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="560" name="onnx::ReduceMean_705" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::ReduceMean_705" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::ReduceMean_705" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="561" name="Constant_4903" type="Const" version="opset1">
			<data element_type="i64" offset="1348" shape="2" size="16"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_4903" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="562" name="input.287" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<rt_info>
				<attribute name="fused_names" value="input.287" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.287" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="563" name="encoder.model.blocks.4.0.se.conv_reduce.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="419804" shape="72, 288, 1, 1" size="41472"/>
			<output>
				<port id="0" precision="FP16">
					<dim>72</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="564" name="encoder.model.blocks.4.0.se.conv_reduce.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="encoder.model.blocks.4.0.se.conv_reduce.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>72</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="encoder.model.blocks.4.0.se.conv_reduce.weight" precision="FP32">
					<dim>72</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="565" name="Convolution_4905" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="2, 2" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_4905" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>72</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="566" name="Reshape_4925_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="461276" shape="1, 72, 1, 1" size="144"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="567" name="Reshape_4925" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="568" name="input.291" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_4924, Reshape_4925, input.291" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.291" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="569" name="onnx::Conv_708" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_708" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_708" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="570" name="encoder.model.blocks.4.0.se.conv_expand.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="461420" shape="288, 72, 1, 1" size="41472"/>
			<output>
				<port id="0" precision="FP16">
					<dim>288</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="571" name="encoder.model.blocks.4.0.se.conv_expand.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="encoder.model.blocks.4.0.se.conv_expand.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>288</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="encoder.model.blocks.4.0.se.conv_expand.weight" precision="FP32">
					<dim>288</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="572" name="Convolution_4954" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="2, 2" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_4954" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>288</dim>
					<dim>72</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="573" name="Reshape_4974_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="502892" shape="1, 288, 1, 1" size="576"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="574" name="Reshape_4974" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="575" name="input.295" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_4973, Reshape_4974, input.295" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.295" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="576" name="Constant_5002_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="577" name="Constant_5002" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_5002" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="578" name="Constant_5003_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="579" name="Constant_5003" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_5003" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="580" name="onnx::Mul_710" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_710" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_710" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="581" name="input.299" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="input.299" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.299" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="582" name="onnx::Conv_899_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="503468" shape="96, 288, 1, 1" size="55296"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="583" name="onnx::Conv_899" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_899" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_899" precision="FP32">
					<dim>96</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="584" name="Convolution_5006" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="2, 2" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_5006" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>288</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>96</dim>
					<dim>288</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="585" name="Reshape_5026_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="558764" shape="1, 96, 1, 1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="586" name="Reshape_5026" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="587" name="input.307" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_5025, Reshape_5026, input.307" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.307" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="588" name="onnx::Conv_902_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="558956" shape="576, 96, 1, 1" size="110592"/>
			<output>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="589" name="onnx::Conv_902" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_902" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_902" precision="FP32">
					<dim>576</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="590" name="Convolution_5054" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="2, 2" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_5054" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>576</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="591" name="Reshape_5074_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="669548" shape="1, 576, 1, 1" size="1152"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="592" name="Reshape_5074" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="593" name="input.315" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_5073, Reshape_5074, input.315" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.315" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="594" name="Constant_5102_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="595" name="Constant_5102" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_5102" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="596" name="Constant_5103_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="597" name="Constant_5103" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_5103" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="598" name="onnx::Mul_716" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_716" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_716" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="599" name="onnx::Conv_717" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_717" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Conv_717" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="600" name="Reshape_5113_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="670700" shape="576, 1, 1, 5, 5" size="28800"/>
			<output>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="601" name="Reshape_5113" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="602" name="GroupConvolution_5179" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="2, 2" pads_begin="4, 4" pads_end="4, 4" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="GroupConvolution_5179, Reshape_5113" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="603" name="Reshape_5199_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="699500" shape="1, 576, 1, 1" size="1152"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="604" name="Reshape_5199" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="605" name="input.323" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_5198, Reshape_5199, input.323" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.323" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="606" name="Constant_5227_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="607" name="Constant_5227" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_5227" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="608" name="Constant_5228_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="609" name="Constant_5228" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_5228" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="610" name="onnx::Mul_720" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_720" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_720" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="611" name="onnx::ReduceMean_721" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::ReduceMean_721" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::ReduceMean_721" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="612" name="Constant_5231" type="Const" version="opset1">
			<data element_type="i64" offset="1348" shape="2" size="16"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_5231" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="613" name="input.327" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<rt_info>
				<attribute name="fused_names" value="input.327" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.327" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="614" name="encoder.model.blocks.4.1.se.conv_reduce.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="700652" shape="144, 576, 1, 1" size="165888"/>
			<output>
				<port id="0" precision="FP16">
					<dim>144</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="615" name="encoder.model.blocks.4.1.se.conv_reduce.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="encoder.model.blocks.4.1.se.conv_reduce.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>144</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="encoder.model.blocks.4.1.se.conv_reduce.weight" precision="FP32">
					<dim>144</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="616" name="Convolution_5233" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="2, 2" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_5233" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>144</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="617" name="Reshape_5253_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="866540" shape="1, 144, 1, 1" size="288"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="618" name="Reshape_5253" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="619" name="input.331" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_5252, Reshape_5253, input.331" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.331" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="620" name="onnx::Conv_724" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_724" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_724" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="621" name="encoder.model.blocks.4.1.se.conv_expand.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="866828" shape="576, 144, 1, 1" size="165888"/>
			<output>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="622" name="encoder.model.blocks.4.1.se.conv_expand.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="encoder.model.blocks.4.1.se.conv_expand.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="encoder.model.blocks.4.1.se.conv_expand.weight" precision="FP32">
					<dim>576</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="623" name="Convolution_5282" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="2, 2" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_5282" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>576</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="624" name="Reshape_5302_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1032716" shape="1, 576, 1, 1" size="1152"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="625" name="Reshape_5302" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="626" name="input.335" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_5301, Reshape_5302, input.335" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.335" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="627" name="Constant_5330_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="628" name="Constant_5330" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_5330" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="629" name="Constant_5331_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="630" name="Constant_5331" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_5331" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="631" name="onnx::Mul_726" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_726" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_726" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="632" name="input.339" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="input.339" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.339" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="633" name="onnx::Conv_908_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1033868" shape="96, 576, 1, 1" size="110592"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="634" name="onnx::Conv_908" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_908" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_908" precision="FP32">
					<dim>96</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="635" name="Convolution_5334" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="2, 2" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_5334" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>96</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="636" name="Reshape_5354_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1144460" shape="1, 96, 1, 1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="637" name="Reshape_5354" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="638" name="onnx::Add_907" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_5353, Reshape_5354, onnx::Add_907" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Add_907" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="639" name="onnx::Conv_730" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_730" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Conv_730" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="640" name="onnx::Conv_911_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1144652" shape="576, 96, 1, 1" size="110592"/>
			<output>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="641" name="onnx::Conv_911" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_911" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_911" precision="FP32">
					<dim>576</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="642" name="Convolution_5383" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="2, 2" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_5383" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>576</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="643" name="Reshape_5403_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1255244" shape="1, 576, 1, 1" size="1152"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="644" name="Reshape_5403" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="645" name="input.351" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_5402, Reshape_5403, input.351" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.351" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="646" name="Constant_5431_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="647" name="Constant_5431" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_5431" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="648" name="Constant_5432_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="649" name="Constant_5432" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_5432" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="650" name="onnx::Mul_733" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_733" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_733" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="651" name="onnx::Conv_734" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_734" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Conv_734" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="652" name="Reshape_5442_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1256396" shape="576, 1, 1, 5, 5" size="28800"/>
			<output>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="653" name="Reshape_5442" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="654" name="GroupConvolution_5508" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="2, 2" pads_begin="4, 4" pads_end="4, 4" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="GroupConvolution_5508, Reshape_5442" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>5</dim>
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="655" name="Reshape_5528_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1285196" shape="1, 576, 1, 1" size="1152"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="656" name="Reshape_5528" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="657" name="input.359" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_5527, Reshape_5528, input.359" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.359" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="658" name="Constant_5556_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="659" name="Constant_5556" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_5556" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="660" name="Constant_5557_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="661" name="Constant_5557" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_5557" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="662" name="onnx::Mul_737" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_737" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_737" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="663" name="onnx::ReduceMean_738" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::ReduceMean_738" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::ReduceMean_738" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="664" name="Constant_5560" type="Const" version="opset1">
			<data element_type="i64" offset="1348" shape="2" size="16"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_5560" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="665" name="input.363" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<rt_info>
				<attribute name="fused_names" value="input.363" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.363" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="666" name="encoder.model.blocks.4.2.se.conv_reduce.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1286348" shape="144, 576, 1, 1" size="165888"/>
			<output>
				<port id="0" precision="FP16">
					<dim>144</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="667" name="encoder.model.blocks.4.2.se.conv_reduce.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="encoder.model.blocks.4.2.se.conv_reduce.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>144</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="encoder.model.blocks.4.2.se.conv_reduce.weight" precision="FP32">
					<dim>144</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="668" name="Convolution_5562" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="2, 2" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_5562" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>144</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="669" name="Reshape_5582_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1452236" shape="1, 144, 1, 1" size="288"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="670" name="Reshape_5582" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="671" name="input.367" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_5581, Reshape_5582, input.367" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.367" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="672" name="onnx::Conv_741" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_741" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_741" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="673" name="encoder.model.blocks.4.2.se.conv_expand.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1452524" shape="576, 144, 1, 1" size="165888"/>
			<output>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="674" name="encoder.model.blocks.4.2.se.conv_expand.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="encoder.model.blocks.4.2.se.conv_expand.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="encoder.model.blocks.4.2.se.conv_expand.weight" precision="FP32">
					<dim>576</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="675" name="Convolution_5611" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="2, 2" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_5611" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>576</dim>
					<dim>144</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="676" name="Reshape_5631_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1618412" shape="1, 576, 1, 1" size="1152"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="677" name="Reshape_5631" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="678" name="input.371" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_5630, Reshape_5631, input.371" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.371" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="679" name="Constant_5659_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="680" name="Constant_5659" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_5659" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="681" name="Constant_5660_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="682" name="Constant_5660" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_5660" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="683" name="onnx::Mul_743" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_743" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_743" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="684" name="input.375" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="input.375" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.375" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="685" name="onnx::Conv_917_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1619564" shape="96, 576, 1, 1" size="110592"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="686" name="onnx::Conv_917" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_917" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_917" precision="FP32">
					<dim>96</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="687" name="Convolution_5663" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="2, 2" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_5663" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>96</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="688" name="Reshape_5683_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1730156" shape="1, 96, 1, 1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="689" name="Reshape_5683" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="690" name="onnx::Add_916" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_5682, Reshape_5683, onnx::Add_916" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Add_916" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="691" name="onnx::Conv_747" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_747" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Conv_747" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="692" name="onnx::Conv_920_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1730348" shape="576, 96, 1, 1" size="110592"/>
			<output>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="693" name="onnx::Conv_920" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_920" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_920" precision="FP32">
					<dim>576</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="694" name="Convolution_5712" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="2, 2" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_5712" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>576</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="695" name="Reshape_5732_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1840940" shape="1, 576, 1, 1" size="1152"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="696" name="Reshape_5732" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="697" name="input.387" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_5731, Reshape_5732, input.387" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.387" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="698" name="Constant_5760_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="902" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="699" name="Constant_5760" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_5760" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="700" name="Constant_5761_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="904" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="701" name="Constant_5761" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="Constant_5761" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16"/>
			</input>
			<output>
				<port id="1" precision="FP32"/>
			</output>
		</layer>
		<layer id="702" name="onnx::Mul_750" type="HardSigmoid" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Mul_750" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32"/>
				<port id="2" precision="FP32"/>
			</input>
			<output>
				<port id="3" names="onnx::Mul_750" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="703" name="onnx::Conv_751" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Conv_751" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Conv_751" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="704" name="onnx::Conv_923_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="1842092" shape="256, 576, 1, 1" size="294912"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="705" name="onnx::Conv_923" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_923" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_923" precision="FP32">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="706" name="Convolution_5764" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_5764" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="707" name="Reshape_5784_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="2137004" shape="1, 256, 1, 1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="708" name="Reshape_5784" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="709" name="input.395" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_5783, Reshape_5784, input.395" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.395" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="710" name="onnx::Concat_754" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Concat_754" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Concat_754" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="711" name="Reshape_5821_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="2137516" shape="576, 1, 1, 3, 3" size="10368"/>
			<output>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="712" name="Reshape_5821" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="713" name="input.399" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="12, 12" pads_begin="12, 12" pads_end="12, 12" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Reshape_5821, input.399" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.399" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="714" name="onnx::Conv_926_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="2147884" shape="256, 576, 1, 1" size="294912"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="715" name="onnx::Conv_926" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_926" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_926" precision="FP32">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="716" name="Convolution_5888" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_5888" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="717" name="Reshape_5908_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="2442796" shape="1, 256, 1, 1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="718" name="Reshape_5908" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="719" name="input.407" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_5907, Reshape_5908, input.407" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.407" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="720" name="onnx::Concat_758" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Concat_758" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Concat_758" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="721" name="Reshape_5945_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="2443308" shape="576, 1, 1, 3, 3" size="10368"/>
			<output>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="722" name="Reshape_5945" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="723" name="input.411" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="24, 24" pads_begin="24, 24" pads_end="24, 24" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Reshape_5945, input.411" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.411" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="724" name="onnx::Conv_929_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="2453676" shape="256, 576, 1, 1" size="294912"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="725" name="onnx::Conv_929" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_929" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_929" precision="FP32">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="726" name="Convolution_6012" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_6012" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="727" name="Reshape_6032_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="2748588" shape="1, 256, 1, 1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="728" name="Reshape_6032" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="729" name="input.419" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_6031, Reshape_6032, input.419" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.419" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="730" name="onnx::Concat_762" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Concat_762" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Concat_762" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="731" name="Reshape_6069_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="2749100" shape="576, 1, 1, 3, 3" size="10368"/>
			<output>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="732" name="Reshape_6069" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="733" name="input.423" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="36, 36" pads_begin="36, 36" pads_end="36, 36" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Reshape_6069, input.423" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.423" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="734" name="onnx::Conv_932_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="2759468" shape="256, 576, 1, 1" size="294912"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="735" name="onnx::Conv_932" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_932" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_932" precision="FP32">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="736" name="Convolution_6136" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_6136" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="737" name="Reshape_6156_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="3054380" shape="1, 256, 1, 1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="738" name="Reshape_6156" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="739" name="input.431" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_6155, Reshape_6156, input.431" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.431" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="740" name="onnx::Concat_766" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Concat_766" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Concat_766" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="741" name="Range_6200" type="Const" version="opset1">
			<data element_type="i64" offset="1348" shape="2" size="16"/>
			<output>
				<port id="0" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="742" name="input.435" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<rt_info>
				<attribute name="fused_names" value="Range_6200, input.435" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.435" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="743" name="onnx::Conv_935_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="3054892" shape="256, 576, 1, 1" size="294912"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="744" name="onnx::Conv_935" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_935" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_935" precision="FP32">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="745" name="Convolution_6225" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_6225" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>576</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="746" name="Reshape_6245_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="3349804" shape="1, 256, 1, 1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="747" name="Reshape_6245" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="748" name="input.443" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_6244, Reshape_6245, input.443" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.443" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="749" name="x" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="x" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="x" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="750" name="onnx::Slice_780" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<rt_info>
				<attribute name="fused_names" value="ShapeOf_6308, onnx::Slice_780" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Slice_780" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="751" name="onnx::Slice_782" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Broadcast_6285, ShapeOf_6284, onnx::Concat_784, onnx::Slice_781, onnx::Slice_782, onnx::Slice_783" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Slice_782" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="752" name="onnx::Slice_783" type="Const" version="opset1">
			<data element_type="i64" offset="930" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Broadcast_6285, ShapeOf_6284, onnx::Concat_784, onnx::Slice_781, onnx::Slice_782, onnx::Slice_783" version="0"/>
			</rt_info>
			<output>
				<port id="0" names="onnx::Slice_783" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="753" name="Broadcast_6285" type="Const" version="opset1">
			<data element_type="i64" offset="3350316" shape="1" size="8"/>
			<rt_info>
				<attribute name="fused_names" value="Broadcast_6285, ShapeOf_6284, onnx::Concat_784, onnx::Slice_781, onnx::Slice_782, onnx::Slice_783" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="754" name="onnx::Concat_784" type="StridedSlice" version="opset1">
			<data begin_mask="0" ellipsis_mask="" end_mask="0" new_axis_mask="" shrink_axis_mask=""/>
			<rt_info>
				<attribute name="fused_names" value="Broadcast_6285, ShapeOf_6284, onnx::Concat_784, onnx::Slice_781, onnx::Slice_782, onnx::Slice_783" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
				<port id="2" precision="I64">
					<dim>1</dim>
				</port>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="4" names="onnx::Concat_784" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="755" name="onnx::Gather_767" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Gather_767, onnx::Gather_770" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>576</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Gather_767,onnx::Gather_770" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="756" name="Constant_53524" type="Const" version="opset1">
			<data element_type="i64" offset="1348" shape="2" size="16"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_779" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="757" name="Constant_53525" type="Const" version="opset1">
			<data element_type="i64" offset="922" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="758" name="Gather_53526" type="Gather" version="opset8">
			<data batch_dims="0"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Cast_779, onnx::Concat_785" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
				<port id="2" precision="I64"/>
			</input>
			<output>
				<port id="3" names="onnx::Cast_779,onnx::Concat_785" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="759" name="onnx::Resize_786" type="Concat" version="opset1">
			<data axis="0"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Resize_786" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>2</dim>
				</port>
				<port id="1" precision="I64">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Resize_786" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="760" name="Convert_6310" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="fused_names" value="Convert_6310" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="761" name="Convert_6309" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="fused_names" value="Convert_6309" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="762" name="Divide_6311" type="Divide" version="opset1">
			<data auto_broadcast="numpy" m_pythondiv="true"/>
			<rt_info>
				<attribute name="fused_names" value="Divide_6311" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>4</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="763" name="Constant_93371" type="Const" version="opset1">
			<data element_type="f32" offset="3350324" shape="1" size="4"/>
			<output>
				<port id="0" precision="FP32">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="764" name="Add_6313" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Add_6313" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>4</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="765" name="onnx::Concat_789" type="Interpolate" version="opset4">
			<data antialias="false" coordinate_transformation_mode="pytorch_half_pixel" cube_coeff="-0.75" mode="linear_onnx" nearest_mode="floor" pads_begin="0, 0, 0, 0" pads_end="0, 0, 0, 0" shape_calculation_mode="sizes"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Concat_789" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
				<port id="2" precision="FP32">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="3" names="onnx::Concat_789" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="766" name="input.447" type="Concat" version="opset1">
			<data axis="1"/>
			<rt_info>
				<attribute name="fused_names" value="input.447" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="3" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="4" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="5" names="input.447" precision="FP32">
					<dim>1</dim>
					<dim>1280</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="767" name="onnx::Conv_938_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="3350328" shape="256, 1280, 1, 1" size="655360"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>1280</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="768" name="onnx::Conv_938" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_938" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>1280</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_938" precision="FP32">
					<dim>256</dim>
					<dim>1280</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="769" name="Convolution_6391" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_6391" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>1280</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>1280</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="770" name="Reshape_6411_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="4005688" shape="1, 256, 1, 1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="771" name="Reshape_6411" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="772" name="input.455" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_6410, Reshape_6411, input.455" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.455" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="773" name="input.459" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="input.459" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="1" names="input.459" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="774" name="Reshape_6448_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="4006200" shape="256, 1, 1, 3, 3" size="4608"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="775" name="Reshape_6448" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="776" name="input.463" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="1, 1" pads_end="1, 1" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Reshape_6448, input.463" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.463" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="777" name="onnx::Conv_941_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="4010808" shape="256, 256, 1, 1" size="131072"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="778" name="onnx::Conv_941" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_941" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_941" precision="FP32">
					<dim>256</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="779" name="Convolution_6515" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_6515" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="780" name="Reshape_6535_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="4141880" shape="1, 256, 1, 1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="781" name="Reshape_6535" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="782" name="input.471" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_6534, Reshape_6535, input.471" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.471" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="783" name="input.475" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="input.475" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="1" names="input.475" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="784" name="ShapeOf_6569" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<rt_info>
				<attribute name="fused_names" value="ShapeOf_6569" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="785" name="Convert_6570" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="fused_names" value="Convert_6570" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="786" name="onnx::Resize_800" type="Const" version="opset1">
			<data element_type="f32" offset="4142392" shape="4" size="16"/>
			<output>
				<port id="0" names="onnx::Resize_800" precision="FP32">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="787" name="Multiply_6571" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Multiply_6571, onnx::Resize_800" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>4</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="788" name="Convert_6572" type="Convert" version="opset1">
			<data destination_type="i64"/>
			<rt_info>
				<attribute name="fused_names" value="Convert_6572" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="789" name="onnx::Concat_802" type="Interpolate" version="opset4">
			<data antialias="false" coordinate_transformation_mode="align_corners" cube_coeff="-0.75" mode="linear_onnx" nearest_mode="floor" pads_begin="0, 0, 0, 0" pads_end="0, 0, 0, 0" shape_calculation_mode="scales"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Concat_802, onnx::Resize_800" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
				<port id="2" precision="FP32">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="3" names="onnx::Concat_802" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="790" name="onnx::Conv_944_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="4142408" shape="48, 16, 1, 1" size="1536"/>
			<output>
				<port id="0" precision="FP16">
					<dim>48</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="791" name="onnx::Conv_944" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_944" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>48</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_944" precision="FP32">
					<dim>48</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="792" name="Convolution_6584" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_6584" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>48</dim>
					<dim>16</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="793" name="Reshape_6604_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="4143944" shape="1, 48, 1, 1" size="96"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="794" name="Reshape_6604" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="795" name="input.483" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_6603, Reshape_6604, input.483" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.483" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="796" name="onnx::Concat_805" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Concat_805" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Concat_805" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="797" name="input.487" type="Concat" version="opset1">
			<data axis="1"/>
			<rt_info>
				<attribute name="fused_names" value="input.487" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>48</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.487" precision="FP32">
					<dim>1</dim>
					<dim>304</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="798" name="Reshape_6642_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="4144040" shape="304, 1, 1, 3, 3" size="5472"/>
			<output>
				<port id="0" precision="FP16">
					<dim>304</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="799" name="Reshape_6642" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>304</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>304</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="800" name="input.491" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="1, 1" pads_end="1, 1" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Reshape_6642, input.491" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>304</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>304</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.491" precision="FP32">
					<dim>1</dim>
					<dim>304</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="801" name="onnx::Conv_947_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="4149512" shape="256, 304, 1, 1" size="155648"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>304</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="802" name="onnx::Conv_947" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="onnx::Conv_947" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>304</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Conv_947" precision="FP32">
					<dim>256</dim>
					<dim>304</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="803" name="Convolution_6709" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_6709" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>304</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>256</dim>
					<dim>304</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="804" name="Reshape_6729_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="4305160" shape="1, 256, 1, 1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="805" name="Reshape_6729" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="806" name="input.499" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_6728, Reshape_6729, input.499" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.499" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="807" name="input.503" type="ReLU" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="input.503" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</input>
			<output>
				<port id="1" names="input.503" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="808" name="segmentation_head.0.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="4305672" shape="3, 256, 1, 1" size="1536"/>
			<output>
				<port id="0" precision="FP16">
					<dim>3</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="809" name="segmentation_head.0.weight" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
				<attribute name="fused_names" value="segmentation_head.0.weight" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>3</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="segmentation_head.0.weight" precision="FP32">
					<dim>3</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="810" name="Convolution_6758" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1, 1" pads_begin="0, 0" pads_end="0, 0" strides="1, 1"/>
			<rt_info>
				<attribute name="fused_names" value="Convolution_6758" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>256</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>3</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="811" name="Reshape_6778_compressed" type="Const" version="opset1">
			<data element_type="f16" offset="4307208" shape="1, 3, 1, 1" size="6"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="812" name="Reshape_6778" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="decompression" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="813" name="input.507" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Concat_6777, Reshape_6778, input.507" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="input.507" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="814" name="ShapeOf_6811" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<rt_info>
				<attribute name="fused_names" value="ShapeOf_6811" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="815" name="Convert_6812" type="Convert" version="opset1">
			<data destination_type="f32"/>
			<rt_info>
				<attribute name="fused_names" value="Convert_6812" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="816" name="onnx::Resize_814" type="Const" version="opset1">
			<data element_type="f32" offset="4142392" shape="4" size="16"/>
			<output>
				<port id="0" names="onnx::Resize_814" precision="FP32">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="817" name="Multiply_6813" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<rt_info>
				<attribute name="fused_names" value="Multiply_6813, onnx::Resize_814" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>4</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="818" name="Convert_6814" type="Convert" version="opset1">
			<data destination_type="i64"/>
			<rt_info>
				<attribute name="fused_names" value="Convert_6814" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="819" name="input.511" type="Interpolate" version="opset4">
			<data antialias="false" coordinate_transformation_mode="align_corners" cube_coeff="-0.75" mode="linear_onnx" nearest_mode="floor" pads_begin="0, 0, 0, 0" pads_end="0, 0, 0, 0" shape_calculation_mode="scales"/>
			<rt_info>
				<attribute name="fused_names" value="input.511, onnx::Resize_814" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>128</dim>
					<dim>256</dim>
				</port>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
				<port id="2" precision="FP32">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="3" names="input.511" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>512</dim>
					<dim>1024</dim>
				</port>
			</output>
		</layer>
		<layer id="820" name="Constant_6826" type="Const" version="opset1">
			<data element_type="i64" offset="4307214" shape="4" size="32"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_6826" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="821" name="onnx::Softmax_817" type="Transpose" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="onnx::Softmax_817" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>512</dim>
					<dim>1024</dim>
				</port>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" names="onnx::Softmax_817" precision="FP32">
					<dim>1</dim>
					<dim>1024</dim>
					<dim>512</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="822" name="onnx::Transpose_818" type="SoftMax" version="opset8">
			<data axis="3"/>
			<rt_info>
				<attribute name="fused_names" value="onnx::Transpose_818" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>1024</dim>
					<dim>512</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" names="onnx::Transpose_818" precision="FP32">
					<dim>1</dim>
					<dim>1024</dim>
					<dim>512</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="823" name="Constant_6829" type="Const" version="opset1">
			<data element_type="i64" offset="4307214" shape="4" size="32"/>
			<rt_info>
				<attribute name="fused_names" value="Constant_6829" version="0"/>
			</rt_info>
			<output>
				<port id="0" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="824" name="819" type="Transpose" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="819" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>1024</dim>
					<dim>512</dim>
					<dim>3</dim>
				</port>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" names="819" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>512</dim>
					<dim>1024</dim>
				</port>
			</output>
		</layer>
		<layer id="825" name="819/sink_port_0" type="Result" version="opset1">
			<rt_info>
				<attribute name="fused_names" value="819/sink_port_0" version="0"/>
			</rt_info>
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>3</dim>
					<dim>512</dim>
					<dim>1024</dim>
				</port>
			</input>
		</layer>
	</layers>
	<edges>
		<edge from-layer="0" from-port="0" to-layer="3" to-port="0"/>
		<edge from-layer="1" from-port="0" to-layer="2" to-port="0"/>
		<edge from-layer="2" from-port="1" to-layer="3" to-port="1"/>
		<edge from-layer="3" from-port="2" to-layer="6" to-port="0"/>
		<edge from-layer="4" from-port="0" to-layer="5" to-port="0"/>
		<edge from-layer="5" from-port="1" to-layer="6" to-port="1"/>
		<edge from-layer="6" from-port="2" to-layer="9" to-port="0"/>
		<edge from-layer="7" from-port="0" to-layer="8" to-port="0"/>
		<edge from-layer="8" from-port="1" to-layer="9" to-port="1"/>
		<edge from-layer="9" from-port="2" to-layer="14" to-port="0"/>
		<edge from-layer="9" from-port="2" to-layer="15" to-port="0"/>
		<edge from-layer="10" from-port="0" to-layer="11" to-port="0"/>
		<edge from-layer="11" from-port="1" to-layer="14" to-port="1"/>
		<edge from-layer="12" from-port="0" to-layer="13" to-port="0"/>
		<edge from-layer="13" from-port="1" to-layer="14" to-port="2"/>
		<edge from-layer="14" from-port="3" to-layer="15" to-port="1"/>
		<edge from-layer="15" from-port="2" to-layer="62" to-port="0"/>
		<edge from-layer="15" from-port="2" to-layer="17" to-port="0"/>
		<edge from-layer="16" from-port="0" to-layer="21" to-port="0"/>
		<edge from-layer="17" from-port="1" to-layer="20" to-port="0"/>
		<edge from-layer="17" from-port="1" to-layer="34" to-port="0"/>
		<edge from-layer="18" from-port="0" to-layer="20" to-port="1"/>
		<edge from-layer="19" from-port="0" to-layer="20" to-port="2"/>
		<edge from-layer="20" from-port="3" to-layer="21" to-port="1"/>
		<edge from-layer="21" from-port="2" to-layer="23" to-port="0"/>
		<edge from-layer="21" from-port="2" to-layer="27" to-port="0"/>
		<edge from-layer="21" from-port="2" to-layer="28" to-port="0"/>
		<edge from-layer="22" from-port="0" to-layer="23" to-port="1"/>
		<edge from-layer="23" from-port="2" to-layer="25" to-port="0"/>
		<edge from-layer="24" from-port="0" to-layer="25" to-port="1"/>
		<edge from-layer="25" from-port="2" to-layer="45" to-port="0"/>
		<edge from-layer="26" from-port="0" to-layer="27" to-port="1"/>
		<edge from-layer="27" from-port="2" to-layer="28" to-port="1"/>
		<edge from-layer="28" from-port="2" to-layer="30" to-port="0"/>
		<edge from-layer="29" from-port="0" to-layer="30" to-port="1"/>
		<edge from-layer="30" from-port="2" to-layer="45" to-port="1"/>
		<edge from-layer="31" from-port="0" to-layer="35" to-port="0"/>
		<edge from-layer="32" from-port="0" to-layer="34" to-port="1"/>
		<edge from-layer="33" from-port="0" to-layer="34" to-port="2"/>
		<edge from-layer="34" from-port="3" to-layer="35" to-port="1"/>
		<edge from-layer="35" from-port="2" to-layer="37" to-port="0"/>
		<edge from-layer="35" from-port="2" to-layer="41" to-port="0"/>
		<edge from-layer="35" from-port="2" to-layer="42" to-port="0"/>
		<edge from-layer="36" from-port="0" to-layer="37" to-port="1"/>
		<edge from-layer="37" from-port="2" to-layer="39" to-port="0"/>
		<edge from-layer="38" from-port="0" to-layer="39" to-port="1"/>
		<edge from-layer="39" from-port="2" to-layer="45" to-port="2"/>
		<edge from-layer="40" from-port="0" to-layer="41" to-port="1"/>
		<edge from-layer="41" from-port="2" to-layer="42" to-port="1"/>
		<edge from-layer="42" from-port="2" to-layer="44" to-port="0"/>
		<edge from-layer="43" from-port="0" to-layer="44" to-port="1"/>
		<edge from-layer="44" from-port="2" to-layer="45" to-port="3"/>
		<edge from-layer="45" from-port="4" to-layer="47" to-port="0"/>
		<edge from-layer="46" from-port="0" to-layer="47" to-port="1"/>
		<edge from-layer="47" from-port="2" to-layer="49" to-port="0"/>
		<edge from-layer="48" from-port="0" to-layer="49" to-port="1"/>
		<edge from-layer="49" from-port="2" to-layer="53" to-port="0"/>
		<edge from-layer="50" from-port="0" to-layer="53" to-port="1"/>
		<edge from-layer="51" from-port="0" to-layer="53" to-port="2"/>
		<edge from-layer="52" from-port="0" to-layer="53" to-port="3"/>
		<edge from-layer="53" from-port="4" to-layer="55" to-port="0"/>
		<edge from-layer="54" from-port="0" to-layer="55" to-port="1"/>
		<edge from-layer="55" from-port="2" to-layer="57" to-port="0"/>
		<edge from-layer="56" from-port="0" to-layer="57" to-port="1"/>
		<edge from-layer="57" from-port="2" to-layer="59" to-port="0"/>
		<edge from-layer="58" from-port="0" to-layer="59" to-port="1"/>
		<edge from-layer="59" from-port="2" to-layer="62" to-port="1"/>
		<edge from-layer="59" from-port="3" to-layer="62" to-port="2"/>
		<edge from-layer="60" from-port="0" to-layer="61" to-port="0"/>
		<edge from-layer="61" from-port="1" to-layer="62" to-port="3"/>
		<edge from-layer="62" from-port="4" to-layer="65" to-port="0"/>
		<edge from-layer="63" from-port="0" to-layer="64" to-port="0"/>
		<edge from-layer="64" from-port="1" to-layer="65" to-port="1"/>
		<edge from-layer="65" from-port="2" to-layer="68" to-port="0"/>
		<edge from-layer="66" from-port="0" to-layer="67" to-port="0"/>
		<edge from-layer="67" from-port="1" to-layer="68" to-port="1"/>
		<edge from-layer="68" from-port="2" to-layer="69" to-port="0"/>
		<edge from-layer="69" from-port="1" to-layer="71" to-port="0"/>
		<edge from-layer="69" from-port="1" to-layer="90" to-port="0"/>
		<edge from-layer="70" from-port="0" to-layer="71" to-port="1"/>
		<edge from-layer="71" from-port="2" to-layer="74" to-port="0"/>
		<edge from-layer="72" from-port="0" to-layer="73" to-port="0"/>
		<edge from-layer="73" from-port="1" to-layer="74" to-port="1"/>
		<edge from-layer="74" from-port="2" to-layer="77" to-port="0"/>
		<edge from-layer="75" from-port="0" to-layer="76" to-port="0"/>
		<edge from-layer="76" from-port="1" to-layer="77" to-port="1"/>
		<edge from-layer="77" from-port="2" to-layer="78" to-port="0"/>
		<edge from-layer="78" from-port="1" to-layer="81" to-port="0"/>
		<edge from-layer="79" from-port="0" to-layer="80" to-port="0"/>
		<edge from-layer="80" from-port="1" to-layer="81" to-port="1"/>
		<edge from-layer="81" from-port="2" to-layer="84" to-port="0"/>
		<edge from-layer="82" from-port="0" to-layer="83" to-port="0"/>
		<edge from-layer="83" from-port="1" to-layer="84" to-port="1"/>
		<edge from-layer="84" from-port="2" to-layer="89" to-port="0"/>
		<edge from-layer="85" from-port="0" to-layer="86" to-port="0"/>
		<edge from-layer="86" from-port="1" to-layer="89" to-port="1"/>
		<edge from-layer="87" from-port="0" to-layer="88" to-port="0"/>
		<edge from-layer="88" from-port="1" to-layer="89" to-port="2"/>
		<edge from-layer="89" from-port="3" to-layer="90" to-port="1"/>
		<edge from-layer="90" from-port="2" to-layer="93" to-port="0"/>
		<edge from-layer="91" from-port="0" to-layer="92" to-port="0"/>
		<edge from-layer="92" from-port="1" to-layer="93" to-port="1"/>
		<edge from-layer="93" from-port="2" to-layer="96" to-port="0"/>
		<edge from-layer="94" from-port="0" to-layer="95" to-port="0"/>
		<edge from-layer="95" from-port="1" to-layer="96" to-port="1"/>
		<edge from-layer="96" from-port="2" to-layer="99" to-port="0"/>
		<edge from-layer="96" from-port="2" to-layer="792" to-port="0"/>
		<edge from-layer="97" from-port="0" to-layer="98" to-port="0"/>
		<edge from-layer="98" from-port="1" to-layer="99" to-port="1"/>
		<edge from-layer="99" from-port="2" to-layer="102" to-port="0"/>
		<edge from-layer="100" from-port="0" to-layer="101" to-port="0"/>
		<edge from-layer="101" from-port="1" to-layer="102" to-port="1"/>
		<edge from-layer="102" from-port="2" to-layer="103" to-port="0"/>
		<edge from-layer="103" from-port="1" to-layer="105" to-port="0"/>
		<edge from-layer="103" from-port="1" to-layer="150" to-port="0"/>
		<edge from-layer="104" from-port="0" to-layer="109" to-port="0"/>
		<edge from-layer="105" from-port="1" to-layer="108" to-port="0"/>
		<edge from-layer="105" from-port="1" to-layer="122" to-port="0"/>
		<edge from-layer="106" from-port="0" to-layer="108" to-port="1"/>
		<edge from-layer="107" from-port="0" to-layer="108" to-port="2"/>
		<edge from-layer="108" from-port="3" to-layer="109" to-port="1"/>
		<edge from-layer="109" from-port="2" to-layer="115" to-port="0"/>
		<edge from-layer="109" from-port="2" to-layer="111" to-port="0"/>
		<edge from-layer="109" from-port="2" to-layer="116" to-port="0"/>
		<edge from-layer="110" from-port="0" to-layer="111" to-port="1"/>
		<edge from-layer="111" from-port="2" to-layer="113" to-port="0"/>
		<edge from-layer="112" from-port="0" to-layer="113" to-port="1"/>
		<edge from-layer="113" from-port="2" to-layer="133" to-port="0"/>
		<edge from-layer="114" from-port="0" to-layer="115" to-port="1"/>
		<edge from-layer="115" from-port="2" to-layer="116" to-port="1"/>
		<edge from-layer="116" from-port="2" to-layer="118" to-port="0"/>
		<edge from-layer="117" from-port="0" to-layer="118" to-port="1"/>
		<edge from-layer="118" from-port="2" to-layer="133" to-port="1"/>
		<edge from-layer="119" from-port="0" to-layer="123" to-port="0"/>
		<edge from-layer="120" from-port="0" to-layer="122" to-port="1"/>
		<edge from-layer="121" from-port="0" to-layer="122" to-port="2"/>
		<edge from-layer="122" from-port="3" to-layer="123" to-port="1"/>
		<edge from-layer="123" from-port="2" to-layer="125" to-port="0"/>
		<edge from-layer="123" from-port="2" to-layer="129" to-port="0"/>
		<edge from-layer="123" from-port="2" to-layer="130" to-port="0"/>
		<edge from-layer="124" from-port="0" to-layer="125" to-port="1"/>
		<edge from-layer="125" from-port="2" to-layer="127" to-port="0"/>
		<edge from-layer="126" from-port="0" to-layer="127" to-port="1"/>
		<edge from-layer="127" from-port="2" to-layer="133" to-port="2"/>
		<edge from-layer="128" from-port="0" to-layer="129" to-port="1"/>
		<edge from-layer="129" from-port="2" to-layer="130" to-port="1"/>
		<edge from-layer="130" from-port="2" to-layer="132" to-port="0"/>
		<edge from-layer="131" from-port="0" to-layer="132" to-port="1"/>
		<edge from-layer="132" from-port="2" to-layer="133" to-port="3"/>
		<edge from-layer="133" from-port="4" to-layer="135" to-port="0"/>
		<edge from-layer="134" from-port="0" to-layer="135" to-port="1"/>
		<edge from-layer="135" from-port="2" to-layer="137" to-port="0"/>
		<edge from-layer="136" from-port="0" to-layer="137" to-port="1"/>
		<edge from-layer="137" from-port="2" to-layer="141" to-port="0"/>
		<edge from-layer="138" from-port="0" to-layer="141" to-port="1"/>
		<edge from-layer="139" from-port="0" to-layer="141" to-port="2"/>
		<edge from-layer="140" from-port="0" to-layer="141" to-port="3"/>
		<edge from-layer="141" from-port="4" to-layer="143" to-port="0"/>
		<edge from-layer="142" from-port="0" to-layer="143" to-port="1"/>
		<edge from-layer="143" from-port="2" to-layer="145" to-port="0"/>
		<edge from-layer="144" from-port="0" to-layer="145" to-port="1"/>
		<edge from-layer="145" from-port="2" to-layer="147" to-port="0"/>
		<edge from-layer="146" from-port="0" to-layer="147" to-port="1"/>
		<edge from-layer="147" from-port="2" to-layer="150" to-port="1"/>
		<edge from-layer="147" from-port="3" to-layer="150" to-port="2"/>
		<edge from-layer="148" from-port="0" to-layer="149" to-port="0"/>
		<edge from-layer="149" from-port="1" to-layer="150" to-port="3"/>
		<edge from-layer="150" from-port="4" to-layer="153" to-port="0"/>
		<edge from-layer="151" from-port="0" to-layer="152" to-port="0"/>
		<edge from-layer="152" from-port="1" to-layer="153" to-port="1"/>
		<edge from-layer="153" from-port="2" to-layer="156" to-port="0"/>
		<edge from-layer="154" from-port="0" to-layer="155" to-port="0"/>
		<edge from-layer="155" from-port="1" to-layer="156" to-port="1"/>
		<edge from-layer="156" from-port="2" to-layer="157" to-port="0"/>
		<edge from-layer="157" from-port="1" to-layer="160" to-port="0"/>
		<edge from-layer="158" from-port="0" to-layer="159" to-port="0"/>
		<edge from-layer="159" from-port="1" to-layer="160" to-port="1"/>
		<edge from-layer="160" from-port="2" to-layer="163" to-port="0"/>
		<edge from-layer="161" from-port="0" to-layer="162" to-port="0"/>
		<edge from-layer="162" from-port="1" to-layer="163" to-port="1"/>
		<edge from-layer="163" from-port="2" to-layer="184" to-port="1"/>
		<edge from-layer="163" from-port="2" to-layer="166" to-port="0"/>
		<edge from-layer="164" from-port="0" to-layer="165" to-port="0"/>
		<edge from-layer="165" from-port="1" to-layer="166" to-port="1"/>
		<edge from-layer="166" from-port="2" to-layer="169" to-port="0"/>
		<edge from-layer="167" from-port="0" to-layer="168" to-port="0"/>
		<edge from-layer="168" from-port="1" to-layer="169" to-port="1"/>
		<edge from-layer="169" from-port="2" to-layer="170" to-port="0"/>
		<edge from-layer="170" from-port="1" to-layer="173" to-port="0"/>
		<edge from-layer="171" from-port="0" to-layer="172" to-port="0"/>
		<edge from-layer="172" from-port="1" to-layer="173" to-port="1"/>
		<edge from-layer="173" from-port="2" to-layer="176" to-port="0"/>
		<edge from-layer="174" from-port="0" to-layer="175" to-port="0"/>
		<edge from-layer="175" from-port="1" to-layer="176" to-port="1"/>
		<edge from-layer="176" from-port="2" to-layer="177" to-port="0"/>
		<edge from-layer="177" from-port="1" to-layer="180" to-port="0"/>
		<edge from-layer="178" from-port="0" to-layer="179" to-port="0"/>
		<edge from-layer="179" from-port="1" to-layer="180" to-port="1"/>
		<edge from-layer="180" from-port="2" to-layer="183" to-port="0"/>
		<edge from-layer="181" from-port="0" to-layer="182" to-port="0"/>
		<edge from-layer="182" from-port="1" to-layer="183" to-port="1"/>
		<edge from-layer="183" from-port="2" to-layer="184" to-port="0"/>
		<edge from-layer="184" from-port="2" to-layer="187" to-port="0"/>
		<edge from-layer="185" from-port="0" to-layer="186" to-port="0"/>
		<edge from-layer="186" from-port="1" to-layer="187" to-port="1"/>
		<edge from-layer="187" from-port="2" to-layer="190" to-port="0"/>
		<edge from-layer="188" from-port="0" to-layer="189" to-port="0"/>
		<edge from-layer="189" from-port="1" to-layer="190" to-port="1"/>
		<edge from-layer="190" from-port="2" to-layer="196" to-port="0"/>
		<edge from-layer="190" from-port="2" to-layer="195" to-port="0"/>
		<edge from-layer="191" from-port="0" to-layer="192" to-port="0"/>
		<edge from-layer="192" from-port="1" to-layer="195" to-port="1"/>
		<edge from-layer="193" from-port="0" to-layer="194" to-port="0"/>
		<edge from-layer="194" from-port="1" to-layer="195" to-port="2"/>
		<edge from-layer="195" from-port="3" to-layer="196" to-port="1"/>
		<edge from-layer="196" from-port="2" to-layer="198" to-port="0"/>
		<edge from-layer="196" from-port="2" to-layer="243" to-port="0"/>
		<edge from-layer="197" from-port="0" to-layer="202" to-port="0"/>
		<edge from-layer="198" from-port="1" to-layer="201" to-port="0"/>
		<edge from-layer="198" from-port="1" to-layer="215" to-port="0"/>
		<edge from-layer="199" from-port="0" to-layer="201" to-port="1"/>
		<edge from-layer="200" from-port="0" to-layer="201" to-port="2"/>
		<edge from-layer="201" from-port="3" to-layer="202" to-port="1"/>
		<edge from-layer="202" from-port="2" to-layer="209" to-port="0"/>
		<edge from-layer="202" from-port="2" to-layer="204" to-port="0"/>
		<edge from-layer="202" from-port="2" to-layer="208" to-port="0"/>
		<edge from-layer="203" from-port="0" to-layer="204" to-port="1"/>
		<edge from-layer="204" from-port="2" to-layer="206" to-port="0"/>
		<edge from-layer="205" from-port="0" to-layer="206" to-port="1"/>
		<edge from-layer="206" from-port="2" to-layer="226" to-port="0"/>
		<edge from-layer="207" from-port="0" to-layer="208" to-port="1"/>
		<edge from-layer="208" from-port="2" to-layer="209" to-port="1"/>
		<edge from-layer="209" from-port="2" to-layer="211" to-port="0"/>
		<edge from-layer="210" from-port="0" to-layer="211" to-port="1"/>
		<edge from-layer="211" from-port="2" to-layer="226" to-port="1"/>
		<edge from-layer="212" from-port="0" to-layer="216" to-port="0"/>
		<edge from-layer="213" from-port="0" to-layer="215" to-port="1"/>
		<edge from-layer="214" from-port="0" to-layer="215" to-port="2"/>
		<edge from-layer="215" from-port="3" to-layer="216" to-port="1"/>
		<edge from-layer="216" from-port="2" to-layer="222" to-port="0"/>
		<edge from-layer="216" from-port="2" to-layer="223" to-port="0"/>
		<edge from-layer="216" from-port="2" to-layer="218" to-port="0"/>
		<edge from-layer="217" from-port="0" to-layer="218" to-port="1"/>
		<edge from-layer="218" from-port="2" to-layer="220" to-port="0"/>
		<edge from-layer="219" from-port="0" to-layer="220" to-port="1"/>
		<edge from-layer="220" from-port="2" to-layer="226" to-port="2"/>
		<edge from-layer="221" from-port="0" to-layer="222" to-port="1"/>
		<edge from-layer="222" from-port="2" to-layer="223" to-port="1"/>
		<edge from-layer="223" from-port="2" to-layer="225" to-port="0"/>
		<edge from-layer="224" from-port="0" to-layer="225" to-port="1"/>
		<edge from-layer="225" from-port="2" to-layer="226" to-port="3"/>
		<edge from-layer="226" from-port="4" to-layer="228" to-port="0"/>
		<edge from-layer="227" from-port="0" to-layer="228" to-port="1"/>
		<edge from-layer="228" from-port="2" to-layer="230" to-port="0"/>
		<edge from-layer="229" from-port="0" to-layer="230" to-port="1"/>
		<edge from-layer="230" from-port="2" to-layer="234" to-port="0"/>
		<edge from-layer="231" from-port="0" to-layer="234" to-port="1"/>
		<edge from-layer="232" from-port="0" to-layer="234" to-port="2"/>
		<edge from-layer="233" from-port="0" to-layer="234" to-port="3"/>
		<edge from-layer="234" from-port="4" to-layer="236" to-port="0"/>
		<edge from-layer="235" from-port="0" to-layer="236" to-port="1"/>
		<edge from-layer="236" from-port="2" to-layer="238" to-port="0"/>
		<edge from-layer="237" from-port="0" to-layer="238" to-port="1"/>
		<edge from-layer="238" from-port="2" to-layer="240" to-port="0"/>
		<edge from-layer="239" from-port="0" to-layer="240" to-port="1"/>
		<edge from-layer="240" from-port="2" to-layer="243" to-port="1"/>
		<edge from-layer="240" from-port="3" to-layer="243" to-port="2"/>
		<edge from-layer="241" from-port="0" to-layer="242" to-port="0"/>
		<edge from-layer="242" from-port="1" to-layer="243" to-port="3"/>
		<edge from-layer="243" from-port="4" to-layer="246" to-port="0"/>
		<edge from-layer="244" from-port="0" to-layer="245" to-port="0"/>
		<edge from-layer="245" from-port="1" to-layer="246" to-port="1"/>
		<edge from-layer="246" from-port="2" to-layer="249" to-port="0"/>
		<edge from-layer="247" from-port="0" to-layer="248" to-port="0"/>
		<edge from-layer="248" from-port="1" to-layer="249" to-port="1"/>
		<edge from-layer="249" from-port="2" to-layer="254" to-port="0"/>
		<edge from-layer="249" from-port="2" to-layer="255" to-port="0"/>
		<edge from-layer="250" from-port="0" to-layer="251" to-port="0"/>
		<edge from-layer="251" from-port="1" to-layer="254" to-port="1"/>
		<edge from-layer="252" from-port="0" to-layer="253" to-port="0"/>
		<edge from-layer="253" from-port="1" to-layer="254" to-port="2"/>
		<edge from-layer="254" from-port="3" to-layer="255" to-port="1"/>
		<edge from-layer="255" from-port="2" to-layer="257" to-port="0"/>
		<edge from-layer="255" from-port="2" to-layer="276" to-port="0"/>
		<edge from-layer="256" from-port="0" to-layer="257" to-port="1"/>
		<edge from-layer="257" from-port="2" to-layer="260" to-port="0"/>
		<edge from-layer="258" from-port="0" to-layer="259" to-port="0"/>
		<edge from-layer="259" from-port="1" to-layer="260" to-port="1"/>
		<edge from-layer="260" from-port="2" to-layer="263" to-port="0"/>
		<edge from-layer="261" from-port="0" to-layer="262" to-port="0"/>
		<edge from-layer="262" from-port="1" to-layer="263" to-port="1"/>
		<edge from-layer="263" from-port="2" to-layer="264" to-port="0"/>
		<edge from-layer="264" from-port="1" to-layer="267" to-port="0"/>
		<edge from-layer="265" from-port="0" to-layer="266" to-port="0"/>
		<edge from-layer="266" from-port="1" to-layer="267" to-port="1"/>
		<edge from-layer="267" from-port="2" to-layer="270" to-port="0"/>
		<edge from-layer="268" from-port="0" to-layer="269" to-port="0"/>
		<edge from-layer="269" from-port="1" to-layer="270" to-port="1"/>
		<edge from-layer="270" from-port="2" to-layer="275" to-port="0"/>
		<edge from-layer="271" from-port="0" to-layer="272" to-port="0"/>
		<edge from-layer="272" from-port="1" to-layer="275" to-port="1"/>
		<edge from-layer="273" from-port="0" to-layer="274" to-port="0"/>
		<edge from-layer="274" from-port="1" to-layer="275" to-port="2"/>
		<edge from-layer="275" from-port="3" to-layer="276" to-port="1"/>
		<edge from-layer="276" from-port="2" to-layer="279" to-port="0"/>
		<edge from-layer="277" from-port="0" to-layer="278" to-port="0"/>
		<edge from-layer="278" from-port="1" to-layer="279" to-port="1"/>
		<edge from-layer="279" from-port="2" to-layer="282" to-port="0"/>
		<edge from-layer="280" from-port="0" to-layer="281" to-port="0"/>
		<edge from-layer="281" from-port="1" to-layer="282" to-port="1"/>
		<edge from-layer="282" from-port="2" to-layer="285" to-port="0"/>
		<edge from-layer="282" from-port="2" to-layer="334" to-port="1"/>
		<edge from-layer="283" from-port="0" to-layer="284" to-port="0"/>
		<edge from-layer="284" from-port="1" to-layer="285" to-port="1"/>
		<edge from-layer="285" from-port="2" to-layer="288" to-port="0"/>
		<edge from-layer="286" from-port="0" to-layer="287" to-port="0"/>
		<edge from-layer="287" from-port="1" to-layer="288" to-port="1"/>
		<edge from-layer="288" from-port="2" to-layer="293" to-port="0"/>
		<edge from-layer="288" from-port="2" to-layer="294" to-port="0"/>
		<edge from-layer="289" from-port="0" to-layer="290" to-port="0"/>
		<edge from-layer="290" from-port="1" to-layer="293" to-port="1"/>
		<edge from-layer="291" from-port="0" to-layer="292" to-port="0"/>
		<edge from-layer="292" from-port="1" to-layer="293" to-port="2"/>
		<edge from-layer="293" from-port="3" to-layer="294" to-port="1"/>
		<edge from-layer="294" from-port="2" to-layer="297" to-port="0"/>
		<edge from-layer="295" from-port="0" to-layer="296" to-port="0"/>
		<edge from-layer="296" from-port="1" to-layer="297" to-port="1"/>
		<edge from-layer="297" from-port="2" to-layer="300" to-port="0"/>
		<edge from-layer="298" from-port="0" to-layer="299" to-port="0"/>
		<edge from-layer="299" from-port="1" to-layer="300" to-port="1"/>
		<edge from-layer="300" from-port="2" to-layer="305" to-port="0"/>
		<edge from-layer="300" from-port="2" to-layer="306" to-port="0"/>
		<edge from-layer="301" from-port="0" to-layer="302" to-port="0"/>
		<edge from-layer="302" from-port="1" to-layer="305" to-port="1"/>
		<edge from-layer="303" from-port="0" to-layer="304" to-port="0"/>
		<edge from-layer="304" from-port="1" to-layer="305" to-port="2"/>
		<edge from-layer="305" from-port="3" to-layer="306" to-port="1"/>
		<edge from-layer="306" from-port="2" to-layer="308" to-port="0"/>
		<edge from-layer="306" from-port="2" to-layer="327" to-port="0"/>
		<edge from-layer="307" from-port="0" to-layer="308" to-port="1"/>
		<edge from-layer="308" from-port="2" to-layer="311" to-port="0"/>
		<edge from-layer="309" from-port="0" to-layer="310" to-port="0"/>
		<edge from-layer="310" from-port="1" to-layer="311" to-port="1"/>
		<edge from-layer="311" from-port="2" to-layer="314" to-port="0"/>
		<edge from-layer="312" from-port="0" to-layer="313" to-port="0"/>
		<edge from-layer="313" from-port="1" to-layer="314" to-port="1"/>
		<edge from-layer="314" from-port="2" to-layer="315" to-port="0"/>
		<edge from-layer="315" from-port="1" to-layer="318" to-port="0"/>
		<edge from-layer="316" from-port="0" to-layer="317" to-port="0"/>
		<edge from-layer="317" from-port="1" to-layer="318" to-port="1"/>
		<edge from-layer="318" from-port="2" to-layer="321" to-port="0"/>
		<edge from-layer="319" from-port="0" to-layer="320" to-port="0"/>
		<edge from-layer="320" from-port="1" to-layer="321" to-port="1"/>
		<edge from-layer="321" from-port="2" to-layer="326" to-port="0"/>
		<edge from-layer="322" from-port="0" to-layer="323" to-port="0"/>
		<edge from-layer="323" from-port="1" to-layer="326" to-port="1"/>
		<edge from-layer="324" from-port="0" to-layer="325" to-port="0"/>
		<edge from-layer="325" from-port="1" to-layer="326" to-port="2"/>
		<edge from-layer="326" from-port="3" to-layer="327" to-port="1"/>
		<edge from-layer="327" from-port="2" to-layer="330" to-port="0"/>
		<edge from-layer="328" from-port="0" to-layer="329" to-port="0"/>
		<edge from-layer="329" from-port="1" to-layer="330" to-port="1"/>
		<edge from-layer="330" from-port="2" to-layer="333" to-port="0"/>
		<edge from-layer="331" from-port="0" to-layer="332" to-port="0"/>
		<edge from-layer="332" from-port="1" to-layer="333" to-port="1"/>
		<edge from-layer="333" from-port="2" to-layer="334" to-port="0"/>
		<edge from-layer="334" from-port="2" to-layer="337" to-port="0"/>
		<edge from-layer="334" from-port="2" to-layer="386" to-port="1"/>
		<edge from-layer="335" from-port="0" to-layer="336" to-port="0"/>
		<edge from-layer="336" from-port="1" to-layer="337" to-port="1"/>
		<edge from-layer="337" from-port="2" to-layer="340" to-port="0"/>
		<edge from-layer="338" from-port="0" to-layer="339" to-port="0"/>
		<edge from-layer="339" from-port="1" to-layer="340" to-port="1"/>
		<edge from-layer="340" from-port="2" to-layer="346" to-port="0"/>
		<edge from-layer="340" from-port="2" to-layer="345" to-port="0"/>
		<edge from-layer="341" from-port="0" to-layer="342" to-port="0"/>
		<edge from-layer="342" from-port="1" to-layer="345" to-port="1"/>
		<edge from-layer="343" from-port="0" to-layer="344" to-port="0"/>
		<edge from-layer="344" from-port="1" to-layer="345" to-port="2"/>
		<edge from-layer="345" from-port="3" to-layer="346" to-port="1"/>
		<edge from-layer="346" from-port="2" to-layer="349" to-port="0"/>
		<edge from-layer="347" from-port="0" to-layer="348" to-port="0"/>
		<edge from-layer="348" from-port="1" to-layer="349" to-port="1"/>
		<edge from-layer="349" from-port="2" to-layer="352" to-port="0"/>
		<edge from-layer="350" from-port="0" to-layer="351" to-port="0"/>
		<edge from-layer="351" from-port="1" to-layer="352" to-port="1"/>
		<edge from-layer="352" from-port="2" to-layer="357" to-port="0"/>
		<edge from-layer="352" from-port="2" to-layer="358" to-port="0"/>
		<edge from-layer="353" from-port="0" to-layer="354" to-port="0"/>
		<edge from-layer="354" from-port="1" to-layer="357" to-port="1"/>
		<edge from-layer="355" from-port="0" to-layer="356" to-port="0"/>
		<edge from-layer="356" from-port="1" to-layer="357" to-port="2"/>
		<edge from-layer="357" from-port="3" to-layer="358" to-port="1"/>
		<edge from-layer="358" from-port="2" to-layer="360" to-port="0"/>
		<edge from-layer="358" from-port="2" to-layer="379" to-port="0"/>
		<edge from-layer="359" from-port="0" to-layer="360" to-port="1"/>
		<edge from-layer="360" from-port="2" to-layer="363" to-port="0"/>
		<edge from-layer="361" from-port="0" to-layer="362" to-port="0"/>
		<edge from-layer="362" from-port="1" to-layer="363" to-port="1"/>
		<edge from-layer="363" from-port="2" to-layer="366" to-port="0"/>
		<edge from-layer="364" from-port="0" to-layer="365" to-port="0"/>
		<edge from-layer="365" from-port="1" to-layer="366" to-port="1"/>
		<edge from-layer="366" from-port="2" to-layer="367" to-port="0"/>
		<edge from-layer="367" from-port="1" to-layer="370" to-port="0"/>
		<edge from-layer="368" from-port="0" to-layer="369" to-port="0"/>
		<edge from-layer="369" from-port="1" to-layer="370" to-port="1"/>
		<edge from-layer="370" from-port="2" to-layer="373" to-port="0"/>
		<edge from-layer="371" from-port="0" to-layer="372" to-port="0"/>
		<edge from-layer="372" from-port="1" to-layer="373" to-port="1"/>
		<edge from-layer="373" from-port="2" to-layer="378" to-port="0"/>
		<edge from-layer="374" from-port="0" to-layer="375" to-port="0"/>
		<edge from-layer="375" from-port="1" to-layer="378" to-port="1"/>
		<edge from-layer="376" from-port="0" to-layer="377" to-port="0"/>
		<edge from-layer="377" from-port="1" to-layer="378" to-port="2"/>
		<edge from-layer="378" from-port="3" to-layer="379" to-port="1"/>
		<edge from-layer="379" from-port="2" to-layer="382" to-port="0"/>
		<edge from-layer="380" from-port="0" to-layer="381" to-port="0"/>
		<edge from-layer="381" from-port="1" to-layer="382" to-port="1"/>
		<edge from-layer="382" from-port="2" to-layer="385" to-port="0"/>
		<edge from-layer="383" from-port="0" to-layer="384" to-port="0"/>
		<edge from-layer="384" from-port="1" to-layer="385" to-port="1"/>
		<edge from-layer="385" from-port="2" to-layer="386" to-port="0"/>
		<edge from-layer="386" from-port="2" to-layer="389" to-port="0"/>
		<edge from-layer="387" from-port="0" to-layer="388" to-port="0"/>
		<edge from-layer="388" from-port="1" to-layer="389" to-port="1"/>
		<edge from-layer="389" from-port="2" to-layer="392" to-port="0"/>
		<edge from-layer="390" from-port="0" to-layer="391" to-port="0"/>
		<edge from-layer="391" from-port="1" to-layer="392" to-port="1"/>
		<edge from-layer="392" from-port="2" to-layer="397" to-port="0"/>
		<edge from-layer="392" from-port="2" to-layer="398" to-port="0"/>
		<edge from-layer="393" from-port="0" to-layer="394" to-port="0"/>
		<edge from-layer="394" from-port="1" to-layer="397" to-port="1"/>
		<edge from-layer="395" from-port="0" to-layer="396" to-port="0"/>
		<edge from-layer="396" from-port="1" to-layer="397" to-port="2"/>
		<edge from-layer="397" from-port="3" to-layer="398" to-port="1"/>
		<edge from-layer="398" from-port="2" to-layer="401" to-port="0"/>
		<edge from-layer="399" from-port="0" to-layer="400" to-port="0"/>
		<edge from-layer="400" from-port="1" to-layer="401" to-port="1"/>
		<edge from-layer="401" from-port="2" to-layer="404" to-port="0"/>
		<edge from-layer="402" from-port="0" to-layer="403" to-port="0"/>
		<edge from-layer="403" from-port="1" to-layer="404" to-port="1"/>
		<edge from-layer="404" from-port="2" to-layer="409" to-port="0"/>
		<edge from-layer="404" from-port="2" to-layer="410" to-port="0"/>
		<edge from-layer="405" from-port="0" to-layer="406" to-port="0"/>
		<edge from-layer="406" from-port="1" to-layer="409" to-port="1"/>
		<edge from-layer="407" from-port="0" to-layer="408" to-port="0"/>
		<edge from-layer="408" from-port="1" to-layer="409" to-port="2"/>
		<edge from-layer="409" from-port="3" to-layer="410" to-port="1"/>
		<edge from-layer="410" from-port="2" to-layer="412" to-port="0"/>
		<edge from-layer="410" from-port="2" to-layer="431" to-port="0"/>
		<edge from-layer="411" from-port="0" to-layer="412" to-port="1"/>
		<edge from-layer="412" from-port="2" to-layer="415" to-port="0"/>
		<edge from-layer="413" from-port="0" to-layer="414" to-port="0"/>
		<edge from-layer="414" from-port="1" to-layer="415" to-port="1"/>
		<edge from-layer="415" from-port="2" to-layer="418" to-port="0"/>
		<edge from-layer="416" from-port="0" to-layer="417" to-port="0"/>
		<edge from-layer="417" from-port="1" to-layer="418" to-port="1"/>
		<edge from-layer="418" from-port="2" to-layer="419" to-port="0"/>
		<edge from-layer="419" from-port="1" to-layer="422" to-port="0"/>
		<edge from-layer="420" from-port="0" to-layer="421" to-port="0"/>
		<edge from-layer="421" from-port="1" to-layer="422" to-port="1"/>
		<edge from-layer="422" from-port="2" to-layer="425" to-port="0"/>
		<edge from-layer="423" from-port="0" to-layer="424" to-port="0"/>
		<edge from-layer="424" from-port="1" to-layer="425" to-port="1"/>
		<edge from-layer="425" from-port="2" to-layer="430" to-port="0"/>
		<edge from-layer="426" from-port="0" to-layer="427" to-port="0"/>
		<edge from-layer="427" from-port="1" to-layer="430" to-port="1"/>
		<edge from-layer="428" from-port="0" to-layer="429" to-port="0"/>
		<edge from-layer="429" from-port="1" to-layer="430" to-port="2"/>
		<edge from-layer="430" from-port="3" to-layer="431" to-port="1"/>
		<edge from-layer="431" from-port="2" to-layer="434" to-port="0"/>
		<edge from-layer="432" from-port="0" to-layer="433" to-port="0"/>
		<edge from-layer="433" from-port="1" to-layer="434" to-port="1"/>
		<edge from-layer="434" from-port="2" to-layer="437" to-port="0"/>
		<edge from-layer="435" from-port="0" to-layer="436" to-port="0"/>
		<edge from-layer="436" from-port="1" to-layer="437" to-port="1"/>
		<edge from-layer="437" from-port="2" to-layer="440" to-port="0"/>
		<edge from-layer="437" from-port="2" to-layer="489" to-port="1"/>
		<edge from-layer="438" from-port="0" to-layer="439" to-port="0"/>
		<edge from-layer="439" from-port="1" to-layer="440" to-port="1"/>
		<edge from-layer="440" from-port="2" to-layer="443" to-port="0"/>
		<edge from-layer="441" from-port="0" to-layer="442" to-port="0"/>
		<edge from-layer="442" from-port="1" to-layer="443" to-port="1"/>
		<edge from-layer="443" from-port="2" to-layer="448" to-port="0"/>
		<edge from-layer="443" from-port="2" to-layer="449" to-port="0"/>
		<edge from-layer="444" from-port="0" to-layer="445" to-port="0"/>
		<edge from-layer="445" from-port="1" to-layer="448" to-port="1"/>
		<edge from-layer="446" from-port="0" to-layer="447" to-port="0"/>
		<edge from-layer="447" from-port="1" to-layer="448" to-port="2"/>
		<edge from-layer="448" from-port="3" to-layer="449" to-port="1"/>
		<edge from-layer="449" from-port="2" to-layer="452" to-port="0"/>
		<edge from-layer="450" from-port="0" to-layer="451" to-port="0"/>
		<edge from-layer="451" from-port="1" to-layer="452" to-port="1"/>
		<edge from-layer="452" from-port="2" to-layer="455" to-port="0"/>
		<edge from-layer="453" from-port="0" to-layer="454" to-port="0"/>
		<edge from-layer="454" from-port="1" to-layer="455" to-port="1"/>
		<edge from-layer="455" from-port="2" to-layer="460" to-port="0"/>
		<edge from-layer="455" from-port="2" to-layer="461" to-port="0"/>
		<edge from-layer="456" from-port="0" to-layer="457" to-port="0"/>
		<edge from-layer="457" from-port="1" to-layer="460" to-port="1"/>
		<edge from-layer="458" from-port="0" to-layer="459" to-port="0"/>
		<edge from-layer="459" from-port="1" to-layer="460" to-port="2"/>
		<edge from-layer="460" from-port="3" to-layer="461" to-port="1"/>
		<edge from-layer="461" from-port="2" to-layer="482" to-port="0"/>
		<edge from-layer="461" from-port="2" to-layer="463" to-port="0"/>
		<edge from-layer="462" from-port="0" to-layer="463" to-port="1"/>
		<edge from-layer="463" from-port="2" to-layer="466" to-port="0"/>
		<edge from-layer="464" from-port="0" to-layer="465" to-port="0"/>
		<edge from-layer="465" from-port="1" to-layer="466" to-port="1"/>
		<edge from-layer="466" from-port="2" to-layer="469" to-port="0"/>
		<edge from-layer="467" from-port="0" to-layer="468" to-port="0"/>
		<edge from-layer="468" from-port="1" to-layer="469" to-port="1"/>
		<edge from-layer="469" from-port="2" to-layer="470" to-port="0"/>
		<edge from-layer="470" from-port="1" to-layer="473" to-port="0"/>
		<edge from-layer="471" from-port="0" to-layer="472" to-port="0"/>
		<edge from-layer="472" from-port="1" to-layer="473" to-port="1"/>
		<edge from-layer="473" from-port="2" to-layer="476" to-port="0"/>
		<edge from-layer="474" from-port="0" to-layer="475" to-port="0"/>
		<edge from-layer="475" from-port="1" to-layer="476" to-port="1"/>
		<edge from-layer="476" from-port="2" to-layer="481" to-port="0"/>
		<edge from-layer="477" from-port="0" to-layer="478" to-port="0"/>
		<edge from-layer="478" from-port="1" to-layer="481" to-port="1"/>
		<edge from-layer="479" from-port="0" to-layer="480" to-port="0"/>
		<edge from-layer="480" from-port="1" to-layer="481" to-port="2"/>
		<edge from-layer="481" from-port="3" to-layer="482" to-port="1"/>
		<edge from-layer="482" from-port="2" to-layer="485" to-port="0"/>
		<edge from-layer="483" from-port="0" to-layer="484" to-port="0"/>
		<edge from-layer="484" from-port="1" to-layer="485" to-port="1"/>
		<edge from-layer="485" from-port="2" to-layer="488" to-port="0"/>
		<edge from-layer="486" from-port="0" to-layer="487" to-port="0"/>
		<edge from-layer="487" from-port="1" to-layer="488" to-port="1"/>
		<edge from-layer="488" from-port="2" to-layer="489" to-port="0"/>
		<edge from-layer="489" from-port="2" to-layer="492" to-port="0"/>
		<edge from-layer="490" from-port="0" to-layer="491" to-port="0"/>
		<edge from-layer="491" from-port="1" to-layer="492" to-port="1"/>
		<edge from-layer="492" from-port="2" to-layer="495" to-port="0"/>
		<edge from-layer="493" from-port="0" to-layer="494" to-port="0"/>
		<edge from-layer="494" from-port="1" to-layer="495" to-port="1"/>
		<edge from-layer="495" from-port="2" to-layer="500" to-port="0"/>
		<edge from-layer="495" from-port="2" to-layer="501" to-port="0"/>
		<edge from-layer="496" from-port="0" to-layer="497" to-port="0"/>
		<edge from-layer="497" from-port="1" to-layer="500" to-port="1"/>
		<edge from-layer="498" from-port="0" to-layer="499" to-port="0"/>
		<edge from-layer="499" from-port="1" to-layer="500" to-port="2"/>
		<edge from-layer="500" from-port="3" to-layer="501" to-port="1"/>
		<edge from-layer="501" from-port="2" to-layer="503" to-port="0"/>
		<edge from-layer="501" from-port="2" to-layer="548" to-port="0"/>
		<edge from-layer="502" from-port="0" to-layer="507" to-port="0"/>
		<edge from-layer="503" from-port="1" to-layer="506" to-port="0"/>
		<edge from-layer="503" from-port="1" to-layer="520" to-port="0"/>
		<edge from-layer="504" from-port="0" to-layer="506" to-port="1"/>
		<edge from-layer="505" from-port="0" to-layer="506" to-port="2"/>
		<edge from-layer="506" from-port="3" to-layer="507" to-port="1"/>
		<edge from-layer="507" from-port="2" to-layer="513" to-port="0"/>
		<edge from-layer="507" from-port="2" to-layer="509" to-port="0"/>
		<edge from-layer="507" from-port="2" to-layer="514" to-port="0"/>
		<edge from-layer="508" from-port="0" to-layer="509" to-port="1"/>
		<edge from-layer="509" from-port="2" to-layer="511" to-port="0"/>
		<edge from-layer="510" from-port="0" to-layer="511" to-port="1"/>
		<edge from-layer="511" from-port="2" to-layer="531" to-port="0"/>
		<edge from-layer="512" from-port="0" to-layer="513" to-port="1"/>
		<edge from-layer="513" from-port="2" to-layer="514" to-port="1"/>
		<edge from-layer="514" from-port="2" to-layer="516" to-port="0"/>
		<edge from-layer="515" from-port="0" to-layer="516" to-port="1"/>
		<edge from-layer="516" from-port="2" to-layer="531" to-port="1"/>
		<edge from-layer="517" from-port="0" to-layer="521" to-port="0"/>
		<edge from-layer="518" from-port="0" to-layer="520" to-port="1"/>
		<edge from-layer="519" from-port="0" to-layer="520" to-port="2"/>
		<edge from-layer="520" from-port="3" to-layer="521" to-port="1"/>
		<edge from-layer="521" from-port="2" to-layer="523" to-port="0"/>
		<edge from-layer="521" from-port="2" to-layer="527" to-port="0"/>
		<edge from-layer="521" from-port="2" to-layer="528" to-port="0"/>
		<edge from-layer="522" from-port="0" to-layer="523" to-port="1"/>
		<edge from-layer="523" from-port="2" to-layer="525" to-port="0"/>
		<edge from-layer="524" from-port="0" to-layer="525" to-port="1"/>
		<edge from-layer="525" from-port="2" to-layer="531" to-port="2"/>
		<edge from-layer="526" from-port="0" to-layer="527" to-port="1"/>
		<edge from-layer="527" from-port="2" to-layer="528" to-port="1"/>
		<edge from-layer="528" from-port="2" to-layer="530" to-port="0"/>
		<edge from-layer="529" from-port="0" to-layer="530" to-port="1"/>
		<edge from-layer="530" from-port="2" to-layer="531" to-port="3"/>
		<edge from-layer="531" from-port="4" to-layer="533" to-port="0"/>
		<edge from-layer="532" from-port="0" to-layer="533" to-port="1"/>
		<edge from-layer="533" from-port="2" to-layer="535" to-port="0"/>
		<edge from-layer="534" from-port="0" to-layer="535" to-port="1"/>
		<edge from-layer="535" from-port="2" to-layer="539" to-port="0"/>
		<edge from-layer="536" from-port="0" to-layer="539" to-port="1"/>
		<edge from-layer="537" from-port="0" to-layer="539" to-port="2"/>
		<edge from-layer="538" from-port="0" to-layer="539" to-port="3"/>
		<edge from-layer="539" from-port="4" to-layer="541" to-port="0"/>
		<edge from-layer="540" from-port="0" to-layer="541" to-port="1"/>
		<edge from-layer="541" from-port="2" to-layer="543" to-port="0"/>
		<edge from-layer="542" from-port="0" to-layer="543" to-port="1"/>
		<edge from-layer="543" from-port="2" to-layer="545" to-port="0"/>
		<edge from-layer="544" from-port="0" to-layer="545" to-port="1"/>
		<edge from-layer="545" from-port="2" to-layer="548" to-port="1"/>
		<edge from-layer="545" from-port="3" to-layer="548" to-port="2"/>
		<edge from-layer="546" from-port="0" to-layer="547" to-port="0"/>
		<edge from-layer="547" from-port="1" to-layer="548" to-port="3"/>
		<edge from-layer="548" from-port="4" to-layer="551" to-port="0"/>
		<edge from-layer="549" from-port="0" to-layer="550" to-port="0"/>
		<edge from-layer="550" from-port="1" to-layer="551" to-port="1"/>
		<edge from-layer="551" from-port="2" to-layer="554" to-port="0"/>
		<edge from-layer="552" from-port="0" to-layer="553" to-port="0"/>
		<edge from-layer="553" from-port="1" to-layer="554" to-port="1"/>
		<edge from-layer="554" from-port="2" to-layer="559" to-port="0"/>
		<edge from-layer="554" from-port="2" to-layer="560" to-port="0"/>
		<edge from-layer="555" from-port="0" to-layer="556" to-port="0"/>
		<edge from-layer="556" from-port="1" to-layer="559" to-port="1"/>
		<edge from-layer="557" from-port="0" to-layer="558" to-port="0"/>
		<edge from-layer="558" from-port="1" to-layer="559" to-port="2"/>
		<edge from-layer="559" from-port="3" to-layer="560" to-port="1"/>
		<edge from-layer="560" from-port="2" to-layer="581" to-port="0"/>
		<edge from-layer="560" from-port="2" to-layer="562" to-port="0"/>
		<edge from-layer="561" from-port="0" to-layer="562" to-port="1"/>
		<edge from-layer="562" from-port="2" to-layer="565" to-port="0"/>
		<edge from-layer="563" from-port="0" to-layer="564" to-port="0"/>
		<edge from-layer="564" from-port="1" to-layer="565" to-port="1"/>
		<edge from-layer="565" from-port="2" to-layer="568" to-port="0"/>
		<edge from-layer="566" from-port="0" to-layer="567" to-port="0"/>
		<edge from-layer="567" from-port="1" to-layer="568" to-port="1"/>
		<edge from-layer="568" from-port="2" to-layer="569" to-port="0"/>
		<edge from-layer="569" from-port="1" to-layer="572" to-port="0"/>
		<edge from-layer="570" from-port="0" to-layer="571" to-port="0"/>
		<edge from-layer="571" from-port="1" to-layer="572" to-port="1"/>
		<edge from-layer="572" from-port="2" to-layer="575" to-port="0"/>
		<edge from-layer="573" from-port="0" to-layer="574" to-port="0"/>
		<edge from-layer="574" from-port="1" to-layer="575" to-port="1"/>
		<edge from-layer="575" from-port="2" to-layer="580" to-port="0"/>
		<edge from-layer="576" from-port="0" to-layer="577" to-port="0"/>
		<edge from-layer="577" from-port="1" to-layer="580" to-port="1"/>
		<edge from-layer="578" from-port="0" to-layer="579" to-port="0"/>
		<edge from-layer="579" from-port="1" to-layer="580" to-port="2"/>
		<edge from-layer="580" from-port="3" to-layer="581" to-port="1"/>
		<edge from-layer="581" from-port="2" to-layer="584" to-port="0"/>
		<edge from-layer="582" from-port="0" to-layer="583" to-port="0"/>
		<edge from-layer="583" from-port="1" to-layer="584" to-port="1"/>
		<edge from-layer="584" from-port="2" to-layer="587" to-port="0"/>
		<edge from-layer="585" from-port="0" to-layer="586" to-port="0"/>
		<edge from-layer="586" from-port="1" to-layer="587" to-port="1"/>
		<edge from-layer="587" from-port="2" to-layer="590" to-port="0"/>
		<edge from-layer="587" from-port="2" to-layer="639" to-port="1"/>
		<edge from-layer="588" from-port="0" to-layer="589" to-port="0"/>
		<edge from-layer="589" from-port="1" to-layer="590" to-port="1"/>
		<edge from-layer="590" from-port="2" to-layer="593" to-port="0"/>
		<edge from-layer="591" from-port="0" to-layer="592" to-port="0"/>
		<edge from-layer="592" from-port="1" to-layer="593" to-port="1"/>
		<edge from-layer="593" from-port="2" to-layer="598" to-port="0"/>
		<edge from-layer="593" from-port="2" to-layer="599" to-port="0"/>
		<edge from-layer="594" from-port="0" to-layer="595" to-port="0"/>
		<edge from-layer="595" from-port="1" to-layer="598" to-port="1"/>
		<edge from-layer="596" from-port="0" to-layer="597" to-port="0"/>
		<edge from-layer="597" from-port="1" to-layer="598" to-port="2"/>
		<edge from-layer="598" from-port="3" to-layer="599" to-port="1"/>
		<edge from-layer="599" from-port="2" to-layer="602" to-port="0"/>
		<edge from-layer="600" from-port="0" to-layer="601" to-port="0"/>
		<edge from-layer="601" from-port="1" to-layer="602" to-port="1"/>
		<edge from-layer="602" from-port="2" to-layer="605" to-port="0"/>
		<edge from-layer="603" from-port="0" to-layer="604" to-port="0"/>
		<edge from-layer="604" from-port="1" to-layer="605" to-port="1"/>
		<edge from-layer="605" from-port="2" to-layer="610" to-port="0"/>
		<edge from-layer="605" from-port="2" to-layer="611" to-port="0"/>
		<edge from-layer="606" from-port="0" to-layer="607" to-port="0"/>
		<edge from-layer="607" from-port="1" to-layer="610" to-port="1"/>
		<edge from-layer="608" from-port="0" to-layer="609" to-port="0"/>
		<edge from-layer="609" from-port="1" to-layer="610" to-port="2"/>
		<edge from-layer="610" from-port="3" to-layer="611" to-port="1"/>
		<edge from-layer="611" from-port="2" to-layer="632" to-port="0"/>
		<edge from-layer="611" from-port="2" to-layer="613" to-port="0"/>
		<edge from-layer="612" from-port="0" to-layer="613" to-port="1"/>
		<edge from-layer="613" from-port="2" to-layer="616" to-port="0"/>
		<edge from-layer="614" from-port="0" to-layer="615" to-port="0"/>
		<edge from-layer="615" from-port="1" to-layer="616" to-port="1"/>
		<edge from-layer="616" from-port="2" to-layer="619" to-port="0"/>
		<edge from-layer="617" from-port="0" to-layer="618" to-port="0"/>
		<edge from-layer="618" from-port="1" to-layer="619" to-port="1"/>
		<edge from-layer="619" from-port="2" to-layer="620" to-port="0"/>
		<edge from-layer="620" from-port="1" to-layer="623" to-port="0"/>
		<edge from-layer="621" from-port="0" to-layer="622" to-port="0"/>
		<edge from-layer="622" from-port="1" to-layer="623" to-port="1"/>
		<edge from-layer="623" from-port="2" to-layer="626" to-port="0"/>
		<edge from-layer="624" from-port="0" to-layer="625" to-port="0"/>
		<edge from-layer="625" from-port="1" to-layer="626" to-port="1"/>
		<edge from-layer="626" from-port="2" to-layer="631" to-port="0"/>
		<edge from-layer="627" from-port="0" to-layer="628" to-port="0"/>
		<edge from-layer="628" from-port="1" to-layer="631" to-port="1"/>
		<edge from-layer="629" from-port="0" to-layer="630" to-port="0"/>
		<edge from-layer="630" from-port="1" to-layer="631" to-port="2"/>
		<edge from-layer="631" from-port="3" to-layer="632" to-port="1"/>
		<edge from-layer="632" from-port="2" to-layer="635" to-port="0"/>
		<edge from-layer="633" from-port="0" to-layer="634" to-port="0"/>
		<edge from-layer="634" from-port="1" to-layer="635" to-port="1"/>
		<edge from-layer="635" from-port="2" to-layer="638" to-port="0"/>
		<edge from-layer="636" from-port="0" to-layer="637" to-port="0"/>
		<edge from-layer="637" from-port="1" to-layer="638" to-port="1"/>
		<edge from-layer="638" from-port="2" to-layer="639" to-port="0"/>
		<edge from-layer="639" from-port="2" to-layer="642" to-port="0"/>
		<edge from-layer="639" from-port="2" to-layer="691" to-port="1"/>
		<edge from-layer="640" from-port="0" to-layer="641" to-port="0"/>
		<edge from-layer="641" from-port="1" to-layer="642" to-port="1"/>
		<edge from-layer="642" from-port="2" to-layer="645" to-port="0"/>
		<edge from-layer="643" from-port="0" to-layer="644" to-port="0"/>
		<edge from-layer="644" from-port="1" to-layer="645" to-port="1"/>
		<edge from-layer="645" from-port="2" to-layer="650" to-port="0"/>
		<edge from-layer="645" from-port="2" to-layer="651" to-port="0"/>
		<edge from-layer="646" from-port="0" to-layer="647" to-port="0"/>
		<edge from-layer="647" from-port="1" to-layer="650" to-port="1"/>
		<edge from-layer="648" from-port="0" to-layer="649" to-port="0"/>
		<edge from-layer="649" from-port="1" to-layer="650" to-port="2"/>
		<edge from-layer="650" from-port="3" to-layer="651" to-port="1"/>
		<edge from-layer="651" from-port="2" to-layer="654" to-port="0"/>
		<edge from-layer="652" from-port="0" to-layer="653" to-port="0"/>
		<edge from-layer="653" from-port="1" to-layer="654" to-port="1"/>
		<edge from-layer="654" from-port="2" to-layer="657" to-port="0"/>
		<edge from-layer="655" from-port="0" to-layer="656" to-port="0"/>
		<edge from-layer="656" from-port="1" to-layer="657" to-port="1"/>
		<edge from-layer="657" from-port="2" to-layer="662" to-port="0"/>
		<edge from-layer="657" from-port="2" to-layer="663" to-port="0"/>
		<edge from-layer="658" from-port="0" to-layer="659" to-port="0"/>
		<edge from-layer="659" from-port="1" to-layer="662" to-port="1"/>
		<edge from-layer="660" from-port="0" to-layer="661" to-port="0"/>
		<edge from-layer="661" from-port="1" to-layer="662" to-port="2"/>
		<edge from-layer="662" from-port="3" to-layer="663" to-port="1"/>
		<edge from-layer="663" from-port="2" to-layer="684" to-port="0"/>
		<edge from-layer="663" from-port="2" to-layer="665" to-port="0"/>
		<edge from-layer="664" from-port="0" to-layer="665" to-port="1"/>
		<edge from-layer="665" from-port="2" to-layer="668" to-port="0"/>
		<edge from-layer="666" from-port="0" to-layer="667" to-port="0"/>
		<edge from-layer="667" from-port="1" to-layer="668" to-port="1"/>
		<edge from-layer="668" from-port="2" to-layer="671" to-port="0"/>
		<edge from-layer="669" from-port="0" to-layer="670" to-port="0"/>
		<edge from-layer="670" from-port="1" to-layer="671" to-port="1"/>
		<edge from-layer="671" from-port="2" to-layer="672" to-port="0"/>
		<edge from-layer="672" from-port="1" to-layer="675" to-port="0"/>
		<edge from-layer="673" from-port="0" to-layer="674" to-port="0"/>
		<edge from-layer="674" from-port="1" to-layer="675" to-port="1"/>
		<edge from-layer="675" from-port="2" to-layer="678" to-port="0"/>
		<edge from-layer="676" from-port="0" to-layer="677" to-port="0"/>
		<edge from-layer="677" from-port="1" to-layer="678" to-port="1"/>
		<edge from-layer="678" from-port="2" to-layer="683" to-port="0"/>
		<edge from-layer="679" from-port="0" to-layer="680" to-port="0"/>
		<edge from-layer="680" from-port="1" to-layer="683" to-port="1"/>
		<edge from-layer="681" from-port="0" to-layer="682" to-port="0"/>
		<edge from-layer="682" from-port="1" to-layer="683" to-port="2"/>
		<edge from-layer="683" from-port="3" to-layer="684" to-port="1"/>
		<edge from-layer="684" from-port="2" to-layer="687" to-port="0"/>
		<edge from-layer="685" from-port="0" to-layer="686" to-port="0"/>
		<edge from-layer="686" from-port="1" to-layer="687" to-port="1"/>
		<edge from-layer="687" from-port="2" to-layer="690" to-port="0"/>
		<edge from-layer="688" from-port="0" to-layer="689" to-port="0"/>
		<edge from-layer="689" from-port="1" to-layer="690" to-port="1"/>
		<edge from-layer="690" from-port="2" to-layer="691" to-port="0"/>
		<edge from-layer="691" from-port="2" to-layer="694" to-port="0"/>
		<edge from-layer="692" from-port="0" to-layer="693" to-port="0"/>
		<edge from-layer="693" from-port="1" to-layer="694" to-port="1"/>
		<edge from-layer="694" from-port="2" to-layer="697" to-port="0"/>
		<edge from-layer="695" from-port="0" to-layer="696" to-port="0"/>
		<edge from-layer="696" from-port="1" to-layer="697" to-port="1"/>
		<edge from-layer="697" from-port="2" to-layer="702" to-port="0"/>
		<edge from-layer="697" from-port="2" to-layer="703" to-port="0"/>
		<edge from-layer="698" from-port="0" to-layer="699" to-port="0"/>
		<edge from-layer="699" from-port="1" to-layer="702" to-port="1"/>
		<edge from-layer="700" from-port="0" to-layer="701" to-port="0"/>
		<edge from-layer="701" from-port="1" to-layer="702" to-port="2"/>
		<edge from-layer="702" from-port="3" to-layer="703" to-port="1"/>
		<edge from-layer="703" from-port="2" to-layer="755" to-port="0"/>
		<edge from-layer="703" from-port="2" to-layer="733" to-port="0"/>
		<edge from-layer="703" from-port="2" to-layer="742" to-port="0"/>
		<edge from-layer="703" from-port="2" to-layer="723" to-port="0"/>
		<edge from-layer="703" from-port="2" to-layer="713" to-port="0"/>
		<edge from-layer="703" from-port="2" to-layer="706" to-port="0"/>
		<edge from-layer="704" from-port="0" to-layer="705" to-port="0"/>
		<edge from-layer="705" from-port="1" to-layer="706" to-port="1"/>
		<edge from-layer="706" from-port="2" to-layer="709" to-port="0"/>
		<edge from-layer="707" from-port="0" to-layer="708" to-port="0"/>
		<edge from-layer="708" from-port="1" to-layer="709" to-port="1"/>
		<edge from-layer="709" from-port="2" to-layer="710" to-port="0"/>
		<edge from-layer="710" from-port="1" to-layer="766" to-port="0"/>
		<edge from-layer="711" from-port="0" to-layer="712" to-port="0"/>
		<edge from-layer="712" from-port="1" to-layer="713" to-port="1"/>
		<edge from-layer="713" from-port="2" to-layer="716" to-port="0"/>
		<edge from-layer="714" from-port="0" to-layer="715" to-port="0"/>
		<edge from-layer="715" from-port="1" to-layer="716" to-port="1"/>
		<edge from-layer="716" from-port="2" to-layer="719" to-port="0"/>
		<edge from-layer="717" from-port="0" to-layer="718" to-port="0"/>
		<edge from-layer="718" from-port="1" to-layer="719" to-port="1"/>
		<edge from-layer="719" from-port="2" to-layer="720" to-port="0"/>
		<edge from-layer="720" from-port="1" to-layer="766" to-port="1"/>
		<edge from-layer="721" from-port="0" to-layer="722" to-port="0"/>
		<edge from-layer="722" from-port="1" to-layer="723" to-port="1"/>
		<edge from-layer="723" from-port="2" to-layer="726" to-port="0"/>
		<edge from-layer="724" from-port="0" to-layer="725" to-port="0"/>
		<edge from-layer="725" from-port="1" to-layer="726" to-port="1"/>
		<edge from-layer="726" from-port="2" to-layer="729" to-port="0"/>
		<edge from-layer="727" from-port="0" to-layer="728" to-port="0"/>
		<edge from-layer="728" from-port="1" to-layer="729" to-port="1"/>
		<edge from-layer="729" from-port="2" to-layer="730" to-port="0"/>
		<edge from-layer="730" from-port="1" to-layer="766" to-port="2"/>
		<edge from-layer="731" from-port="0" to-layer="732" to-port="0"/>
		<edge from-layer="732" from-port="1" to-layer="733" to-port="1"/>
		<edge from-layer="733" from-port="2" to-layer="736" to-port="0"/>
		<edge from-layer="734" from-port="0" to-layer="735" to-port="0"/>
		<edge from-layer="735" from-port="1" to-layer="736" to-port="1"/>
		<edge from-layer="736" from-port="2" to-layer="739" to-port="0"/>
		<edge from-layer="737" from-port="0" to-layer="738" to-port="0"/>
		<edge from-layer="738" from-port="1" to-layer="739" to-port="1"/>
		<edge from-layer="739" from-port="2" to-layer="740" to-port="0"/>
		<edge from-layer="740" from-port="1" to-layer="766" to-port="3"/>
		<edge from-layer="741" from-port="0" to-layer="742" to-port="1"/>
		<edge from-layer="742" from-port="2" to-layer="745" to-port="0"/>
		<edge from-layer="743" from-port="0" to-layer="744" to-port="0"/>
		<edge from-layer="744" from-port="1" to-layer="745" to-port="1"/>
		<edge from-layer="745" from-port="2" to-layer="748" to-port="0"/>
		<edge from-layer="746" from-port="0" to-layer="747" to-port="0"/>
		<edge from-layer="747" from-port="1" to-layer="748" to-port="1"/>
		<edge from-layer="748" from-port="2" to-layer="749" to-port="0"/>
		<edge from-layer="749" from-port="1" to-layer="765" to-port="0"/>
		<edge from-layer="749" from-port="1" to-layer="750" to-port="0"/>
		<edge from-layer="750" from-port="1" to-layer="754" to-port="0"/>
		<edge from-layer="750" from-port="1" to-layer="761" to-port="0"/>
		<edge from-layer="751" from-port="0" to-layer="754" to-port="1"/>
		<edge from-layer="752" from-port="0" to-layer="754" to-port="2"/>
		<edge from-layer="753" from-port="0" to-layer="754" to-port="3"/>
		<edge from-layer="754" from-port="4" to-layer="759" to-port="0"/>
		<edge from-layer="755" from-port="1" to-layer="758" to-port="0"/>
		<edge from-layer="756" from-port="0" to-layer="758" to-port="1"/>
		<edge from-layer="757" from-port="0" to-layer="758" to-port="2"/>
		<edge from-layer="758" from-port="3" to-layer="759" to-port="1"/>
		<edge from-layer="759" from-port="2" to-layer="765" to-port="1"/>
		<edge from-layer="759" from-port="2" to-layer="760" to-port="0"/>
		<edge from-layer="760" from-port="1" to-layer="762" to-port="0"/>
		<edge from-layer="761" from-port="1" to-layer="762" to-port="1"/>
		<edge from-layer="762" from-port="2" to-layer="764" to-port="0"/>
		<edge from-layer="763" from-port="0" to-layer="764" to-port="1"/>
		<edge from-layer="764" from-port="2" to-layer="765" to-port="2"/>
		<edge from-layer="765" from-port="3" to-layer="766" to-port="4"/>
		<edge from-layer="766" from-port="5" to-layer="769" to-port="0"/>
		<edge from-layer="767" from-port="0" to-layer="768" to-port="0"/>
		<edge from-layer="768" from-port="1" to-layer="769" to-port="1"/>
		<edge from-layer="769" from-port="2" to-layer="772" to-port="0"/>
		<edge from-layer="770" from-port="0" to-layer="771" to-port="0"/>
		<edge from-layer="771" from-port="1" to-layer="772" to-port="1"/>
		<edge from-layer="772" from-port="2" to-layer="773" to-port="0"/>
		<edge from-layer="773" from-port="1" to-layer="776" to-port="0"/>
		<edge from-layer="774" from-port="0" to-layer="775" to-port="0"/>
		<edge from-layer="775" from-port="1" to-layer="776" to-port="1"/>
		<edge from-layer="776" from-port="2" to-layer="779" to-port="0"/>
		<edge from-layer="777" from-port="0" to-layer="778" to-port="0"/>
		<edge from-layer="778" from-port="1" to-layer="779" to-port="1"/>
		<edge from-layer="779" from-port="2" to-layer="782" to-port="0"/>
		<edge from-layer="780" from-port="0" to-layer="781" to-port="0"/>
		<edge from-layer="781" from-port="1" to-layer="782" to-port="1"/>
		<edge from-layer="782" from-port="2" to-layer="783" to-port="0"/>
		<edge from-layer="783" from-port="1" to-layer="789" to-port="0"/>
		<edge from-layer="783" from-port="1" to-layer="784" to-port="0"/>
		<edge from-layer="784" from-port="1" to-layer="785" to-port="0"/>
		<edge from-layer="785" from-port="1" to-layer="787" to-port="0"/>
		<edge from-layer="786" from-port="0" to-layer="787" to-port="1"/>
		<edge from-layer="786" from-port="0" to-layer="789" to-port="2"/>
		<edge from-layer="787" from-port="2" to-layer="788" to-port="0"/>
		<edge from-layer="788" from-port="1" to-layer="789" to-port="1"/>
		<edge from-layer="789" from-port="3" to-layer="797" to-port="0"/>
		<edge from-layer="790" from-port="0" to-layer="791" to-port="0"/>
		<edge from-layer="791" from-port="1" to-layer="792" to-port="1"/>
		<edge from-layer="792" from-port="2" to-layer="795" to-port="0"/>
		<edge from-layer="793" from-port="0" to-layer="794" to-port="0"/>
		<edge from-layer="794" from-port="1" to-layer="795" to-port="1"/>
		<edge from-layer="795" from-port="2" to-layer="796" to-port="0"/>
		<edge from-layer="796" from-port="1" to-layer="797" to-port="1"/>
		<edge from-layer="797" from-port="2" to-layer="800" to-port="0"/>
		<edge from-layer="798" from-port="0" to-layer="799" to-port="0"/>
		<edge from-layer="799" from-port="1" to-layer="800" to-port="1"/>
		<edge from-layer="800" from-port="2" to-layer="803" to-port="0"/>
		<edge from-layer="801" from-port="0" to-layer="802" to-port="0"/>
		<edge from-layer="802" from-port="1" to-layer="803" to-port="1"/>
		<edge from-layer="803" from-port="2" to-layer="806" to-port="0"/>
		<edge from-layer="804" from-port="0" to-layer="805" to-port="0"/>
		<edge from-layer="805" from-port="1" to-layer="806" to-port="1"/>
		<edge from-layer="806" from-port="2" to-layer="807" to-port="0"/>
		<edge from-layer="807" from-port="1" to-layer="810" to-port="0"/>
		<edge from-layer="808" from-port="0" to-layer="809" to-port="0"/>
		<edge from-layer="809" from-port="1" to-layer="810" to-port="1"/>
		<edge from-layer="810" from-port="2" to-layer="813" to-port="0"/>
		<edge from-layer="811" from-port="0" to-layer="812" to-port="0"/>
		<edge from-layer="812" from-port="1" to-layer="813" to-port="1"/>
		<edge from-layer="813" from-port="2" to-layer="814" to-port="0"/>
		<edge from-layer="813" from-port="2" to-layer="819" to-port="0"/>
		<edge from-layer="814" from-port="1" to-layer="815" to-port="0"/>
		<edge from-layer="815" from-port="1" to-layer="817" to-port="0"/>
		<edge from-layer="816" from-port="0" to-layer="817" to-port="1"/>
		<edge from-layer="816" from-port="0" to-layer="819" to-port="2"/>
		<edge from-layer="817" from-port="2" to-layer="818" to-port="0"/>
		<edge from-layer="818" from-port="1" to-layer="819" to-port="1"/>
		<edge from-layer="819" from-port="3" to-layer="821" to-port="0"/>
		<edge from-layer="820" from-port="0" to-layer="821" to-port="1"/>
		<edge from-layer="821" from-port="2" to-layer="822" to-port="0"/>
		<edge from-layer="822" from-port="1" to-layer="824" to-port="0"/>
		<edge from-layer="823" from-port="0" to-layer="824" to-port="1"/>
		<edge from-layer="824" from-port="2" to-layer="825" to-port="0"/>
	</edges>
	<meta_data>
		<MO_version value="2022.1.0-7019-cdb9bec7210-releases/2022/1"/>
		<Runtime_version value="2022.1.0-7019-cdb9bec7210-releases/2022/1"/>
		<legacy_path value="False"/>
		<cli_parameters>
			<caffe_parser_path value="DIR"/>
			<compress_fp16 value="True"/>
			<data_type value="FP32"/>
			<disable_nhwc_to_nchw value="False"/>
			<disable_omitting_optional value="False"/>
			<disable_resnet_optimization value="False"/>
			<disable_weights_compression value="False"/>
			<enable_concat_optimization value="False"/>
			<enable_flattening_nested_params value="False"/>
			<enable_ssd_gluoncv value="False"/>
			<extensions value="DIR"/>
			<framework value="onnx"/>
			<freeze_placeholder_with_value value="{}"/>
			<input_model value="DIR/lane_model.onnx"/>
			<input_model_is_text value="False"/>
			<input_shape value="[1,3,512,1024]"/>
			<k value="DIR/CustomLayersMapping.xml"/>
			<layout value="()"/>
			<layout_values value="{}"/>
			<legacy_mxnet_model value="False"/>
			<log_level value="ERROR"/>
			<mean_scale_values value="[(array([123.675, 116.28 , 103.53 ]), array([58.395, 57.12 , 57.375]))]"/>
			<mean_values value="[123.675,116.28,103.53]"/>
			<model_name value="lane_model"/>
			<output_dir value="DIR"/>
			<placeholder_data_types value="{}"/>
			<placeholder_shapes value="(1, 3, 512, 1024)"/>
			<progress value="False"/>
			<remove_memory value="False"/>
			<remove_output_softmax value="False"/>
			<reverse_input_channels value="False"/>
			<save_params_from_nd value="False"/>
			<scale_values value="[58.395,57.12,57.375]"/>
			<silent value="False"/>
			<source_layout value="()"/>
			<static_shape value="False"/>
			<stream_output value="False"/>
			<target_layout value="()"/>
			<transform value=""/>
			<use_legacy_frontend value="False"/>
			<use_new_frontend value="False"/>
			<unset unset_cli_parameters="batch, counts, disable_fusing, finegrain_fusing, input, input_checkpoint, input_meta_graph, input_proto, input_symbol, mean_file, mean_file_offsets, nd_prefix_name, output, pretrained_model_name, saved_model_dir, saved_model_tags, scale, tensorboard_logdir, tensorflow_custom_layer_libraries, tensorflow_custom_operations_config_update, tensorflow_object_detection_api_pipeline_config, tensorflow_use_custom_operations_config, transformations_config"/>
		</cli_parameters>
	</meta_data>
</net>
